00:00 【制作人：奔崩】
2020年的时候
00:01 有一篇博客冲到了 Hacker News的第一名
00:05 Hacker News 是在技术圈里面
00:06 应该是影响力最大的一个新闻汇聚网站
00:10 所有人都可以分享自己喜欢的文章
00:12 然后观众呢 对这些文章进行点赞或者是评论
00:15 Hacker News 根据你点赞的个数和评论来进行排名
00:19 这篇文章能排到第一位
00:20 意味着大家还是挺喜欢的
00:22 然后来看一下标题
00:23 标题是说你是不是感觉工作没有状态
00:26 也许你就是应该停止想太多
00:29 这是一个非常鸡汤的标题
00:30 在微信公众号上
00:32 你可能会看到许多类似的文章
00:34 然后我们点进去这篇文章看一下
00:36 他写的还是挺正常的对吧有一个图
00:39 这个配图也是正确的
00:40 然后里面有些文字
00:41 我就不给大家一一讲了
00:43 段落有长有短
00:44 看上去是怎么回事
00:45 然后文章也挺长的
00:47 然后这件事情呢又上了另外一个头条
00:50 这一次上的头条是在
00:52 MIT 的技术评论里面
00:54 这是一个老牌的技术评论杂志
00:57 他的标题叫做 说
00:58 一个大学生做了一个假的
01:01 然后由 ai 生成的博客
01:04 然后呢糊弄了上万人
01:06 事实上我们刚刚看到的那篇文章
01:09 是一个叫做 nothing but words 的博客里面的一篇文章
01:12 这个博客里面其实还有挺多别的文章
01:14 看上去都似模似样
01:15 但是整个博客是由模型生成的
01:19 这个模型叫做 GPT-3
01:21 他文章的第一段话是想说
01:23 在某个星期的早一点时候
01:25 有一个小哥听到了这个模型
01:27 然后呢
01:28 他就在这个信息里面用这个模型
01:30 生成了这样一个博客
01:32 非常的简单
01:33 在过去几年里面
01:34 整个自然语言处理界
01:36 可能最出圈的模型应该就是 GPT-3了
01:39 这个模型来自于 open ai 的团队
01:41 在这个模型放出来之后啊
01:43 整个网络上就把这个模型玩出了花了
01:46 如果你去搜一下 GPT-3的应用的话
01:48 你可以搜出上百个
01:49 比如说我们随便找一篇文章
01:51 给大家看一下里面到底有什么东西
01:53 这片博客呢是写于2020年的7月22号啊
01:57 你现在已经很久了
01:58 当然现在有更多的应用出来
02:00 我们先看一下
02:01 当时候 大家已经有些什么很奇怪的玩法
02:04 它里面呢就转载了当时后大家哦
02:07 用 GPT-3来玩各种应用的一些例子
02:10 比如说这里有个小哥
02:11 用 GPT-3来写一个基于 react 的一个
02:16 丢色子的一个模块
02:18 然后他在方框里面填好说
02:20 我需要一个按钮
02:22 他能够给我来丢色色子
02:24 然后把我的值显现出来
02:26 也把它放进去之后
02:28 然后 GPT-3来给你生成你的 html 代码
02:32 然后你的结果就显示在这个地方
02:34 你看按一下这个地方之后
02:36 他告诉你说现在的指示3
02:38 他又把他的要求改了改
02:40 他说我需要一个Button
02:43 跟之前一样
02:44 然后需要在你输出的时候
02:46 把你的值是3改成你现在
02:49 丢了一个什么东西值出来
02:51 然后用 GPT-3来生成之后
02:54 他又给你生成相应的代码
02:57 然后来看一下效果
02:58 你看这个是 HTML 代码在这个地方
03:00 然后他的结果在这里
03:01 他真的把你的结果
03:03 改成了你要的那个形式
03:05 你多按几次啊
03:06 每一次他就随机生成一个数字
03:08 往下翻呢就是另外一些应用了
03:11 图灵测试是说
03:12 我在墙的后面放一个电脑或放一个人
03:14 你跟他对话
03:15 但是你完全分不出来
03:17 到底他是人还是电脑
03:19 比如说他用来生成的一些
03:21 回答的一些例子
03:22 比如说这个问题说
03:23 你最喜欢的动物是什么
03:25 说我最喜欢狗
03:26 然后你问说你为什么呢
03:27 他说狗啊比较忠诚而且比较友好
03:30 下面一个是一个稍微不一样的问题
03:32 当然是这个是比较相对来说比较简单的啊
03:35 因为他不是很长的对话
03:37 长对话更加难
03:38 因为你得把前面那些
03:39 上下文信息啊都给你记住
03:41 然后下面有一个难一点的啊
03:43 我填一个人名
03:45 让他来模仿这个人说话
03:47 来回答你的问题
03:48 比如说他填的是 Elon Musk
03:50 让你来回答什么是火箭
03:53 然后他就模仿Elon Musk
03:55 给你回答说火箭是长什么样子的
03:57 但这个东西就不好评判
03:58 因为我也不知道 Elon Musk
04:00 真的来讲会怎么样子啊
04:02 下面还有个应用是说
04:03 我在一个方框里面讲
04:05 说我要设计一个什么样的东西出来
04:07 他打了一段非常长的话在里面
04:10 然后再点生成
04:12 可以看到是说
04:13 他可以真的把你这一个东西
04:15 生成 成 你差不多想要的形式
04:18 在这个地方
04:19 最后的例子是说
04:20 我给你一段技术性比较强的话
04:22 然后你把它改写一下
04:24 使得不那么技术的人也能够听懂
04:27 这个地方 他是从 GPT-3的论文里面
04:29 直接 copy 的一段话进去
04:31 然后在这个地方上面把它改
04:34 写成相对来说用比较简单的句式
04:37 每一句都比较短
04:38 然后是因为 所以 因为 所有 这样子的句式
04:40 大家可以去看一下
04:41 当然这个地方只是列了一些应用
04:43 Open AI 呢 他推出了一个GPT-3的一个 API
04:47 使得你能调用这个模型开发你任何想用的应用
04:51 这里有一个网站叫做 GPT-3 demos
04:54 他这个地方列举了目前来说
04:56 我们知道 所有基于 GPT-3的做的一些应用
04:59 可以看到这里面大概有几百个的样子
05:01 各个地方都有啊
05:03 我们来看一下
05:04 都有哪一些比较流行的类别啊
05:06 比如说这个地方用 AI 来辅助你的写作
05:09 然后这个是一个聊天机器人呢
05:11 然后下面还有一些开发工具
05:13 然后所有东西加起来大概有好几百的样子
05:17 最近的一个基于GPT-3的应用
05:19 大家可能也听说过
05:20 这就是 GitHub Copilot
05:22 他的意思是说
05:24 你可以通过注释来说
05:25 我要写一个函数干什么事情
05:27 然后把函数签名给定之后
05:29 剩下的函数的主体就怎么实现它
05:31 可以用代码来自动生成
05:34 这个工作引起了巨大的反响
05:35 在之后有数个工作对他进行了研究
05:38 好这就是对 GPT-3的
05:40 目前的一些应用的一个非常快速的一个预览
05:43 我们今天的任务就是来讲
05:45 GPT-3这篇论文
05:46 如果我们要讲 GPT-3这篇文章
05:48 我们就不得不提到他前面的两个工作
05:51 gpt 2和 gpt
05:53 在这个地方
05:53 我们把这三篇文章
05:54 和我们之前讲过的 transformer BERT 这
05:57 两篇文章分别列在这个地方
05:59 横着这条线表示的是时间轴
06:01 我们可以看到啊
06:02 transformer 我们首先发表在2017年的6月
06:06 在一年之后 gpt 出来了
06:08 我们之前有讲过 gpt 他的核心技术是
06:11 把 transformer 的解码器给你拿出来
06:14 然后在没有标号的大量的文本数据上
06:16 训练一个语言模型
06:18 来获得一个预训练模型
06:20 然后再用他在子任务上做微调
06:22 得到每一个任务所要的分类器
06:25 这个跟我们之前 的计算机视觉用的技术很一样了
06:28 然后在四个月之后
06:29 bert 出来了
06:30 我们之前有提过
06:32 据小道消息是 bert 的一作
06:34 是在一两个月之内把这篇文章做出来的
06:37 很有可能是他在
06:39 看到了 gpt 这篇文章之后才有的 Idea
06:41 BERT的思想是说我跟 gpt 不一样
06:44 我是把 Transformer的编码器拿过来
06:46 然后我收集了一个更大的数据集
06:49 用来做预训练
06:50 结果效果比 gpt 好很多
06:52 我们回忆下
06:53 BERT 里面一共有两个模型
06:55 一个叫 BERT Base  一个叫 BERT large
06:57 BERT Base 的选择就是跟 GPT 的 模型大小是一样的
07:01 BERT large 当然是比 BERT Base 要大一些
07:03 结果上来说
07:04 BERT base 应该是要比 gpt 要好
07:06 而 BERT Large 又甩出了 BERT Base 一条街
07:09 然后在另外4个月之后 GPT2 出现了
07:13 GPT  2呢
07:14 又是原作者这帮人吸取了前面的教训
07:17 哪里跌倒就在哪里爬起来
07:20 他们收集了一个更大的数据集
07:22 训练了一个更大的模型
07:24 GPT  2的模型比 BERT Large是要大的
07:27 如果你就 简简单单的训练了一个大的模型
07:30 那你在新意度上肯定是有问题的
07:32 所以他就沿着了自己的技术路线
07:34 继续使用 transformer 的解码器
07:36 来深入挖掘语言模型的潜力
07:39 然后他发现这个非常适合做 zero Shot
07:42 但是因为你走的比较远啊
07:44 所以导致效果上没有那么的惊艳
07:46 于是在一年又3个月之后
07:48 也就是2020年的5月份
07:50 他们推出了 GPT-3
07:52 GPT-3对 GPT2的改进就是
07:54 数据和模型都大了100倍
07:57 暴力出了奇迹
07:58 然后终于把效果做到非常惊艳
08:01 也就是我们之前看的这些应用的效果
08:03 非常的炸裂
08:04 也就是 GPT-3的效果
08:06 所以这一期视频的封面就是
08:08 暴力出奇迹
08:09 然后我们这里画了两个 logo
08:11 一个是 open ai
08:12 一个是 google
08:14 因为 transformer BERT 都来自于 google 的团队
08:17 然后 GPT 系列三篇文章
08:18 都来自于 open ai 这个团队
08:20 有意思的是 open ai 团队虽然投入了很多
08:23 做了 GPT 系列
08:24 但是他在学术界的影响力似乎是
08:27 不如 bert 的
08:28 这里我们列决到目前为止他们的引用
08:31 BERT 在这篇文章的引用是27,000次
08:33 如果你把 gpt GPT  2
08:35 GPT-3 3篇文章的用加起来
08:37 大概是11,000次的样子
08:39 还不到 BERT 的1/2
08:41 GPT系列他的引用率稍低
08:43 他倒不是因为他的创新度
08:45 或者是他的效果不如BERT 系列
08:47 恰恰相反 我觉得是因为 OpenAI选择去解决 更大的问题
08:52 所以他的技术上实现更难一些
08:54 他出效果更难一些
08:56 比如说你要出到很炸裂的效果
08:58 你得做到 GPT-3
08:59 他这个规模
09:00 几乎是
09:01 没有别的团队能够复现他们结果的
09:04 OpenAI 选择这样子的技术问题 去解决
09:06 是因为他整个公司
09:07 他还是想做强人工智能
09:09 他想去解决一个更大的问题
09:11 所以他们必须在 选择问题上选择大一点
09:13 反过来讲 Transformer BERT 系列
09:15 都是来自于 Google
09:17 独立的一些研究组
09:18 他们一开始想解决的问题
09:20 其实都比较小
09:21 Transformer我们之前有提过
09:22 他其实就想解决机器翻译
09:24 这样子的例子啊
09:25 从一个序列翻译到另外一个序列
09:27 他的上面的效果
09:28 BERT呢其实也是挺实在的
09:30 他就是想把计算机视觉那个成熟的
09:33 先训练一个预训练的模型
09:34 然后再做微调出子任务的结果
09:37 这一套搬过来在 NLP 上做好
09:39 因为他们就是想实实在在提升 技术的效果
09:42 所以呢在同样模型大小
09:45 比如说是一个亿级别 模型大小时候
09:48  bert 的 性能是要好于 gpt 的
09:50 就是未来的工作
09:52 更多愿意用 BERT 的文章
09:54 因为我咬咬牙
09:55 还是能找到足够的机器
09:56 能把我的模型跑起来
09:58 而且效果不错
09:59 不然你如果要跟 gpt 系列的文章的话
10:01 可能帮你卖了你还是跑不起那个实验
10:03 好接下来我们就按顺序从 gpt gpt 2
10:06 GPT-3逐一读一下每一篇文章
10:09 先看 gpt gpt 文章的标题叫做
10:12 使用通用的预训练 来提升语言的理解能力
10:16 gpt 跟我们之前说的很多文章一样
10:19 他并没有给自己的方法起标题
10:22 所以 gpt 的名字来自于后面人给他的
10:25  g p t 这三个字母组合在一起
10:28 如果大家对自己的硬盘
10:30 做过格式化分区的话
10:32 你可能也听说过 gpt
10:34 所以幸好这个工作有一定的知名度
10:36 而且 open ai 的作者在
10:38 之后持续对他改进
10:39 有 gpt 2 GPT-3
10:41 不然的话你现在去搜 gpt 的话
10:43 可能就搜不到这篇文章
10:44 而是搜到的是硬盘如何分区了
10:47 他的作者这里有四个人
10:49 一作是 Alee Radford
10:51 这个人在 gpt 工作之前
10:53 还有挺多有名的工作
10:54 比如说这是他 google scholar 的界面
10:56 可以看到他其实
10:57 引用最高的文章是 DCGAN 这篇文章
11:00 就是用卷积神经网络来替换掉
11:03 GAN 里面的那个 mlp
11:04 另外一个是 ppo
11:05 这也是强化学习里面一个很常见的优化算法
11:09 还有是他又做了一个GAN的工作
11:11 然后后面的三个工作就是 gpt 这三部曲了
11:15 最后一名作者 Ilya
11:16 相信大家还是记得吧
11:18 AlexNet 作者的二作
11:20 然后他去了 OpenAI 担任呢 cto
11:22 所以 OpenAI 呢
11:23 很多工作应该是挂了他的名字
11:24 作为最后一个作者了
11:26 接下来我们来看一下摘要
11:28 摘要写的比较简单
11:29 我们先来看一下前面两句话
11:31 讲的是我要解决什么问题
11:33 他说在自然语言理解里面呢
11:35 有很多不一样的任务
11:37 然后说虽然我们有很多
11:39 大量的没有标号的文本文件
11:42 但是呢
11:43 标好的数据是相对来说比较少的
11:45 这使得我们要去
11:47 在这些标号的数据上
11:48 训练出分辨模型的话
11:50 会比较的难
11:51 因为我们的数据相对来说还是太小了
11:54 接下来就讲作者怎么解决这个问题
11:56 他的解决方法是说
11:58 我们先在没有标号的数据上面训练一个
12:03 预训练模型
12:04 这个预训模型是一个语言模型
12:06 接下来呢
12:07 在 在有标号的这些子任务上面训练一个
12:10 分辨的微调模型
12:12 这个在计算机视觉里面
12:14 早在8、9年前已经是成为主流的算法
12:17 但是在 NLP 领域一直没有流行起来
12:20 是因为在 NLP 里面没有
12:22 像 ImageNet 那么大规模标好的那种数据
12:25 在计算机视觉里面
12:26 我们要标好的100万张图片
12:28 ImageNet在 NLP 的话并没有那么大数据集
12:32 虽然说机器翻译那一块
12:33 我们也许能做到100万的量级
12:36 但是你一个句子和一个图片不在一个尺度上面
12:39 一张图片里面含有的信息
12:41 那个像素的信息比一个句子里面
12:44 能去抽取的信息来的多很多
12:46 所以一张图片可能能换
12:47 10个句子的样子
12:48 那意味着是说
12:49 你至少有1,000万级别的句子级别的
12:52 标好的数据集才能够训练比较大的模型
12:55 这导致在相当一段时间里面
12:58 深度学习在 NLP 的进展
12:59 没有那么的顺利
13:01 直到 gpt 和后面的 bert 的出现
13:03 才打开了局面
13:04 注意这里我们还是像计算机视觉那样
13:07 先训练好预训练模型再来做微调
13:09 但是这个不一样的是说
13:11 我们使用的是没有标号的文本
13:14 这个就往前走了一大步
13:16 然后在 GPT 系列后面的文章在做 Zero Shot
13:19 走了另外一大步
13:20 如果说深度学习前面五年
13:22 主要是计算机视觉在引领整个潮流的话
13:25 那么最近几年可以看到这些创新很多
13:28 来自于自然语言处理界
13:30 而且这些创新也在反馈回计算机视觉里面
13:34 比如说之前我们读过的 mae 这篇文章
13:36 就是把 bert 用回到计算机视觉上面
13:39 我们在上一集介绍了CLIP
13:40 也是打通了文本和图像
13:43 当然在自然语言处理
13:44 用没有标号的文本那也不是第一次了
13:47 比如说十几年前就很火的 word to Vector
13:50 这个词嵌入模型
13:51 就是用的大量的没有标号的文本
13:54 但是他在这里说
13:55 我们跟之前工作的一个区别是说
13:57 他们是在微调的时候
13:59 构造跟你任务相关的输入
14:02 从而使得我们只要很少的改变我们模型的架构就行了
14:07 这是因为文本跟图片不一样
14:09 他的任务更加多样性一些
14:11 有些任务说我要对词进行判断
14:13 有些任务我需要对句子进行判断
14:15 有些任务是说
14:16 我需要一对句子或者三个句子
14:18 还有一些应用是说我要生成一个句子
14:21 所以导致每个任务都需要有自己的模型
14:23 我们最早的词嵌入只是做一个词上面的一个学习
14:27 然后你的后面的模型还得去构造
14:29 之前那些工作
14:30 需要把你的模型进行一些改变
14:32 来适应 各个任务但是这个地方我们只要改变
14:35 输入的形式就行了
14:37 而不需要改变的模型
14:38 当然我们读过 BERT 的话
14:40 我们知道这个是怎么做的
14:41 但是 GPT  是在 BERT 之前
14:43 所以他提出来的时候
14:44 在当时来说当然是有新意的
14:47 最后是写实验结果可以看到
14:48 是说他在12个任务里面
14:50 有9个任务能够超过
14:52 当前最好的成绩
14:54 所以看上去是稍微弱于 bert 之后的结果
14:57 他在十几个用上都超越了前面
15:00 所以导致是说
15:01 bert 为什么出来之后比 gpt
15:04 更加有影响力
15:04 因为他效果更加好一点
15:06 但是从创新度来讲
15:08 我觉得 GPT 应该在 bert 之上
15:10 因为他毕竟是前面的工作
15:12 bert 在很多时候跟他的思路是一样的
15:14 接下来我们来看一下导言
15:16 导言的第一句话
15:17 讲的是我们之前提到的那个问题
15:19 就是怎么样更好的利用无监督的文本
15:23 作者提到在当时候啊
15:25 最成功的模型还是词嵌入模型
15:27 然后接下来第二段话是讲用
15:30 没有标号文本的时候
15:32 使用他遇到的一些困难
15:34 他主要讲了两个困难
15:36 第一个困难是说
15:37 你不知道用什么样的优化目标函数
15:40 就是我给你一堆文本
15:41 你到底你的损失函数长什么样子呢
15:44 当时候有很多选择
15:45 比如说你有语言模型啦
15:47 你有机器翻译啦
15:48 或者是文本的一致性
15:49 但是问题说没有发现某一个特别的好
15:52 就一个目标函数在一些任务上比较好
15:54 另外一个目标函数在
15:55 另外一些问题上就比较好说
15:57 看你的目标函数跟你
15:58 实际要做的子任务
15:59 它的相关度有多高了
16:01 第二个难点是说
16:02 怎么样有效的把你
16:04 学到的这些文本的表示啊
16:06 传递到你下游的子任务上面
16:08 这是因为 NLP 里面的子任务啊
16:10 差别还比较大的
16:11 没有一个简单的统一的有效的方式
16:13 使得一种表示
16:15 能够一致的牵引到所有的子任务上面
16:17 好 接下来第三段就是说 gpt 这本文章呢
16:20 他提出了一个半监督的方法
16:23 然后呢在没有标号的文本上面
16:26 训练一个比较大的语言模型
16:28 然后再在子任务上进行微调
16:30 当然我们现在对这一套比较熟悉啊
16:32 但是有意思的说你回到当年
16:35 作者用的是半监督学习这个词
16:38 叫 semi supervised
16:39 半监督学习啊
16:40 在机器学习界
16:41 可能在十年前是非常的火的
16:44 他的核心思想是说
16:45 我有一些标好的数据
16:46 但我还有大量的
16:47 相似的但没有标好的数据
16:49 我 怎么样把这些没有标号的数据用过来
16:52 那就是半监督学习想学的东西
16:54 这个地方呢
16:55 当然是可以放到半监督学习里面啊
16:58 就是说你在没有标好的模型上面
17:00 训练好一个模型之后
17:01 然后再在有监督的上面做微调
17:04 但是呢 半监督学习里面还有很多别的算法
17:06 但现在我们把 GPT
17:08 这一套方法和 bert 之后
17:10 所有的工作也用到的类似方法
17:12 不叫做半监督学习
17:14 而叫自监督学习
17:16 叫做 self supervised Learning
17:18 这也是上一期的CLIP那篇文章
17:20 作者又说到同一个方法
17:22 但是在不同的论文的作者
17:23 把它归类成不一样的算法
17:25 下一段讲的是他用到的模型
17:28 可以看到他主要是有两点
17:30 第一点是说他的模型是
17:31 基于Transformer 这个架构的
17:33 因为这篇文章发表在
17:35 transformer 这篇文章出来一年之后
17:37 当然 作者在作者工作的时候应该可能更早
17:40 可能是 transformer 出来就几个月
17:42 所以在是用 transformer 还是用 RNN 的模型的时候
17:45 在当时不是那么显而易见的
17:48 所以作者解释了一下大概的原因
17:50 他说跟 RNN 这种模型相比啊
17:53 他发现 transformer 他在迁移学习的时候
17:56 他学到的那些Feature更加的稳健一些
17:59 作者觉得原因可能是因为
18:01 transformer 里面有更结构化的 记忆
18:04 使得能够处理更长的这些文本信息
18:07 从而能够抽取出更好的
18:09 句子层面和段落层面的这些语义信息了
18:12 第二个技术要点是说他在做
18:15 迁移的时候啊
18:16 用的是一个任务相关的输入的一个表示
18:19 我们在之后会看到他到底长什么样子
18:22 最后一段只讲我的试验结果了
18:23 我们就不在这里给大家看了
18:25 下面是相关工作
18:26 相关工作我们就不给大家仔细讲了
18:29 他就讲了一下在
18:30 NLP 里面半监督是怎么回事
18:32 然后讲的是无监督的运行的模型
18:34 还有是说我在训练的时候
18:37 需要使用多个目标函数的时候会怎么样
18:40 这分别对应的是你的大的
18:42 GPT模型怎么样
18:43 在没有标号的数据上训练出来
18:45 以及说你怎么样在
18:47 子任务上运用有标号的数据进行微调
18:50 最后的时候你在做微调的时候
18:51 他使用了两个训练的目标函数
18:54 第三章就是讲这个模型的本身呢
18:56 我们来看一下
18:58 这节里面有三个小节
18:59 分别对应的是
19:00 我怎么在没有标号的数据上训练模型
19:03 怎么样做微调
19:04 以及说
19:04 我怎么样对每个子任务表示我的输入
19:07 我们先来看3.1
19:08 就是在没有标号的数据上面做预训练
19:11 假设我们有一个文本
19:13 没有标号的文本里面每个词呢
19:15 表示成一个 ui
19:17 那么他整个文本就表示成 u1 一直到 ui
19:20 他是有个序列信息的就
19:21 词我们不会交换你的顺序
19:23 GPT 使用一个标准的语言模型 的目标函数
19:27 来最大化下面这个似然函数
19:31 我们来看一下是怎么回事
19:32 具体来说
19:33 语言模型就是要预测
19:34 第i个词出现的概率
19:36 那么第二个词即为 ui
19:38 他怎么预测呢
19:39 他是把 ui 的前面的 k 个词就是 ui 减一
19:44 一直到 ui 减 k
19:46 k 这个地方是你的窗口大小
19:47 或者要做上下文窗口
19:49 也就是说每次我们拿 k 个连续的词
19:52 然后再预测这
19:54 k 个词后面那一个词是谁
19:56 具体来说他的预测是用一个模型
19:57 这个模型记成 Θ 在这个地方
19:59 给定你 k 个词
20:01 给定模型
20:02 那么预测这 k 个词下一个词它的概率
20:05 把每一个这样子的词啊就是 i
20:08 他的位置从零一直到最后
20:11 把全部加起来就得到我们的目标函数
20:14 这个地方即为L1
20:15 他不是你的那个范式里面的L1
20:18 他就是第一个目标函数
20:20 因为他后面还有一个别的目标函数
20:22 他为什么是加是因为取了 log 的缘故
20:24 如果你做指数放回去的话
20:26 那就是所有这些词出现的概率相乘
20:30 也就是这个文本
20:31 出现的联合概率
20:32 就是说我要训练一个模型
20:34 使得他能够
20:35 最大概率的输出
20:37 跟我的文本长得一样的一些文章
20:39 所以这个地方
20:40 Θ模型是你的参数
20:42 k 呢是你的超参数
20:45 就是你的窗口的大小
20:46 从神经网络角度而言
20:47 那你 k 就是你输入序列的长度
20:50 你的序列越长的话
20:51 你的网络看到的东西就越多
20:53 就是他越会倾向于在一个比较长的
20:57 文本里面去找里面的关系
20:59 k 越短的话
21:00 当然你的模型相对说比较简单
21:02 只要看比较短的就行了
21:04 所以这个地方
21:05 如果你想让你的模型很强的话
21:07 那么 k 可能要取到几十
21:09 几百或者甚至上千了
21:11 他在下面又解释了一下
21:13 具体这个模型是谁
21:15 他用到的模型是 transformer 的解码器
21:18 我们回忆一下Transformer有两个东西
21:20 一个是编码器一个是解码器
21:23 他们最大的不一样在于是说
21:25 编码器来一个序列进来
21:27 他对第i个元素抽特征的时候
21:30 他能够看到整个序列里面所有的元素
21:33 但是对解码器来讲因为有掩码的存在
21:36 所以他在对第i个元素抽特征的时候
21:39 他只会看到
21:40 当前元素和他之前的这些元素
21:43 他后面那些元素的东西通过一个掩码
21:46 使得在计算注意力机制的时候变成0
21:48 所以他是不看后面东西的
21:50 这个地方 因为我们用的是标准的语言模型
21:53 我们只对前预测
21:55 我们预测第i个词的时候
21:57 不会看到这个词后面的这些词是谁
21:59 所以一定是往前的这个地方
22:01 所以我们只能使用Transformer的解码器
22:05 而不能使用他的编码器
22:06 然后下面他给了稍微这个模型的一些解释
22:09 当然假设你对Transformer比较了解了
22:11 他说如果我要预测
22:13 u 这个词它的概率的话
22:15 那我们把这个词前面这些词啊
22:16 全部拉出来
22:17 就 k 个词拉出来记成一个大 u
22:19 然后把它做一个投影啊
22:21 就词嵌入的投影
22:22 再加上一个位置信息的编码
22:24 那得到你的第一层的输入
22:26 那么接下来我要做 n 层
22:28 这样子的Transformer 块
22:30 每一层我们把上一次的输出拿进来
22:33 然后得到输出
22:34 因为我们知道
22:34 Transformer块不会改变你的输入输出的形状
22:37 所以你一直做完之后
22:39 最后拿到你最后一个 transformer块的输出
22:41 然后再做一个投影
22:42 用 soft max 就会得到它的概率分布了
22:45 如果大家忘记了 transformer 块是怎么定义的话
22:48 欢迎回到我们之前 Transformer
22:50 这篇文章的讲解视频里面有详细的讲解
22:53 因为我们已经读过了 BERT 这篇文章
22:55 我们稍微来讲一下它跟 BERT 的区别
22:57 BERT 我们知道
22:59 他用的不是标准的语言模型
23:01 他用的是一个带掩码的语言模型
23:03 他就是完形填空
23:05 所以完形填空是说我给一个句子
23:06 我把中间的一个词挖掉
23:08 让你预测中间的
23:10 就是说你在预测的时候
23:11 我既能看见他之前的词
23:13 又能看见之后的词
23:15 所以他可以对应的使用 transformer 的编码器
23:18 因为编码器上看到所有
23:20 所以使用编码器和解码器
23:22 倒不是他们两个的主要的区别
23:24 主要区别在于 你的目标函数的选取
23:27 这个地方 gpt 用的是一个更难的
23:30 就是给前面一段话预测后面一个词
23:33 预测未来当然比完形填空要难
23:36 具体来说
23:37 我给你股票的信息
23:38 到当前的股价之前都知道
23:40 我让你预测明天的股价
23:42 远远的难于是说我告诉你到今天为止的股价
23:46 但是我昨天的股票不告诉你
23:48 然后你预测昨天这个股票的价格
23:50 你都知道过去和未来
23:52 那么中间差值就能得到中间
23:54 就是预测一个开放式的结局
23:56 比预测中间一个状态要难很多
24:00 这也是导致的 gpt 在训练上和效果上
24:03 他其实比BERT 要差一些的一个原因之一吧
24:06 那么反过来讲
24:07 如果你的模型真的能预测未来的话
24:09 那么你比BERT 这种通过完形填空训练模型要强大很多
24:14 这是为什么作者需要
24:15 一直不断的把模型做大
24:17 而且一直不断努力
24:18 才能最后做出 GPT-3那样子
24:20 效果惊艳的模型出来
24:22 这也是我们之前讲到的
24:23 作者选了一个更难的技术路线
24:26 但很有可能他的天花板也就更高了
24:29 所以这就是预训练模型
24:30 这也是为什么我们说
24:31 gpt 就是Transformer的一个解码器
24:33 这简单讲就是这么回事对吧
24:35 接下来我们来看一下他是怎么样做微调的
24:38 在微调任务里面我是有标号的
24:40 具体来说每一次我给你一个长为 m的一个词的序列
24:44 然后我告诉你
24:45 这个序列他对应的标号是 y
24:47 那么就是说
24:48 我们每一次给这个序列去预测他的 y
24:51 具体来讲就
24:52 是说我每次给你 x1 一直到 xm
24:54 我要预测 y 的概率
24:56 他这里的做法是把整个这个序列啊
24:58 放进我们之前训练好的 GPT 模型里面
25:01 然后拿到
25:03 transformer 块的最后一层的输出
25:06 他对应的 hm 这个词的这个输出
25:09 然后再乘以一个输出层
25:11 然后再做一个 soft max
25:12 就得到他的概率了
25:14 是微调任务里面
25:15 所有的带标号的这些序列对
25:17 我们把这个序列 x1 到 xm 输入进去之后
25:21 计算我们真实的那个标号上面的概率
25:24 我们要对他做最大化
25:25 这是一个非常标准的一个分类目标函数
25:28 然后作者说虽然我们在微调的时候
25:31 我们只关心这一个分类的精度
25:33 但如果把
25:34 之前的这个语言模型同样放进来
25:37 效果也不错
25:39 意思是说
25:40 我们在做微调的时候有两个目标函数
25:43 第一个是说给你这些序列
25:45 然后预测序列的下一个词
25:47 和给你完整的序列
25:48 让你预测序列对应的标号
25:51 这两个一起训练效果是最佳的
25:53 然后他通过一个λ
25:55 把这两个目标函数
25:56 加起来最后这个东西是可以调的
25:58 也是一个超参数了
26:00 那我们知道微调长什么样子的情况下
26:02 接下来要考虑的是
26:04 怎么样把 NLP  里面那些很不一样的子任务
26:07 表示成一个我们要的形式
26:09 就是说
26:10 表示成一个序列和他一个对应的标号
26:13 就是第3.3小节要讲的事情了
26:16 我们可以直接通过图一
26:17 就能给大家讲清楚到底是怎么表示的
26:20 这里给了 NLP 里面四大常见的应用
26:23 我们下面来看一看他们都是什么
26:25 一类是最常见的分类
26:27 就说给我一句话或者一段文本
26:29 我来判断他对的一个标号
26:32 比如说一个用户对一个产品的评价
26:34 是正面的还是负面的
26:36 他这里的做法是说
26:37 我把我要分类的这一段文字呀
26:40 在前面放一个初始的词元
26:42 在后面加一个抽取的词元
26:45 然后就做成一个序列
26:47 序列放进 transformer 的解码器里面
26:50 然后模型对最后一个词他抽取的特征啊
26:53 放进一个线性层里面
26:56 线性层的话
26:56 就投影到我要的那个标号的空间
26:59 就是说如果我要做10类分类的话
27:01 那么你的线性层它的输出大小就是10
27:04 在训练的时候
27:05 就是对每一个文本和标号对
27:08 我们把文本变成一个这样子的序列
27:10 然后标号呢就放在这个地方参加训练
27:13 在预测的时候
27:14 当然是说我们只拿到这一个序列信息
27:16 然后对他直接做预测就行了
27:18 所以这个地方跟之前的
27:20 语言模型还是有那么一点区别的
27:22 因为这个线性层啊是我新加的
27:24 这是在微调的时候
27:25 我重新构造了一个新的线性层
27:28 里面的全都可能是随机初始化的
27:30 然后他的输出大小
27:31 跟我的标号的大小是一致的
27:33 第二个英文叫做蕴含
27:35 就是我给你一段话
27:37 然后再问你一个假设
27:38 你看一下我前面这段话
27:40 有没有蕴含我假设提出来的东西
27:43 比如说 a 送给 b 一束玫瑰
27:46 假设我的假设是说 a 喜欢 b
27:48 那么你就说
27:48 我前面这段话是支持你这个假设的
27:51 如果我说
27:52 a 讨厌 b 那么你可以认为
27:55 前面这段话是不支持这个假设的
27:57 如果我说 a 和 b 是邻居
27:59 那么你可以说前面这个假设既不支持
28:02 也不反对我这个假设
28:04 所以说白了就是一个三类的问题
28:06 我给你两段文本
28:07 然后让你做一个三分类的问题
28:09 他在表达的时候
28:10 就是把这两个文本串成一个长的序列
28:13 用一个开始符的地方
28:14 啊分隔符和抽取符
28:17 当注意到我们这里写的是 star 呀
28:19 啊分隔呀和抽取
28:21 但是在真实表达上
28:23 你不能用这个词放进去的
28:24 是因为
28:25 这些词你可能在文本里面也要出现
28:28 所以这三个词元是一个特殊的记号
28:30 必须要跟我的
28:31 词典里面那些别的词是不一样才行的
28:34 不然的话模型就会混淆了
28:36 第三个应用是相似
28:37 就是判断两段文字是不是相似
28:40 这个应用在 NLP 里面用的也是非常广泛
28:42 比如说我一个搜索词
28:44 和我一个文档是不是相似的
28:46 或者说我两个文档是不是相似
28:48 我这样子能来去重
28:50 或者说两个问题问的是不是相似来去重
28:52 因为相似是一个对称的关系
28:54 就说 a 和 b 相似
28:56 那么意味着 b 和 a 也是相似的
28:58 但是我们在语言模型里面是有个先后的顺序
29:01 所以这个地方他做两个序列
29:03 第一个序列里面
29:04 第一段文字放在第二段文字前面
29:07 中间还是一样用分割符分开
29:08 前面加一个起始符和一个结束符
29:11 第二个序列就是把文字1和文字2交换顺序
29:15 第二个序列就是把文字1和文字2交换顺序
29:18 这是因为他的对称关系
29:20 然后这两段
29:22 序列分别进入我的模型之后
29:24 得到最后的这个输出
29:26 然后在上面做加号
29:28 最后进入我的线性层
29:29 得到我们要的
29:31 是相似还是不是相似的一个二分类的问题
29:34 最后是一个多选题
29:35 就是我问你一个问题
29:37 然后给你几个答案
29:38 你在里面选出你觉得正确那个答案
29:42 他的做法是如果你有 n 个答案的话
29:44 那我们就构造 n 个序列
29:46 其中前面的都是你的问题
29:48 然后每一个答案作为第二个序列
29:50 放在这个地方
29:52 每一个序列分别进入你的模型
29:54 然后用一个线性投影层
29:55 他的输出大小是1
29:57 这样得到你这个答案
29:59 是我这个问题
30:00 问到的正确答案的一个置信度
30:02 对每个答案我都算一个这样子的标量
30:04 然后最后做一个 soft max
30:06 就知道我对于这个问题
30:08 我对每个答案
30:09 觉得是他 正确答案的置信度是等于多少了
30:12 可以看到
30:12 虽然这些应用上
30:13 他的数据都长得不那么样
30:15 但是基本上都可以构造成一个序列
30:17 要么就是有一段话要么就是有两段话
30:20 但是分隔开来
30:21 如果更复杂一点的话
30:22 我可以构造出多个序列出来
30:24 但是这个地方不管我的输入形式怎么变
30:28 我的输出他的构造怎么变
30:30 中间这个Transformer模型是不会变的
30:32 就是说我预先练好我的Transformer模型之后
30:35 我在做下游的任务时候
30:37 我都不会对这个模型的结构做改变
30:39 这也是 gpt
30:40 跟之前工作的一个大的区别
30:42 也就是这篇文章卖的一个核心点呐
30:45 讲完模型之后我们来看下他的实验
30:47 实验我们这里不会仔细给大家讲
30:50 大家只要注意到这有两点就是了
30:52 第一点是
30:52 他是在一个叫做
30:54 BooksCorpus 的一个数据集上训练出来的
30:56 这个地方有7,000篇没有被发表的书
31:01 第二个说他的模型呢
31:02 大小是要长成这个样子的
31:04 他用了12层的一个
31:07 transformer 的解码器
31:08 然后每一层的他的维度是768
31:12 所以我们关心的是说
31:13 你用一个多大的模型
31:14 在一个多大的数据集上训练好的
31:17 在结果上他当然比了之前那些算法
31:20 他说我们这样子的方法呀
31:21 比前面的人都要好一点
31:23 这个是 gpt 这个算法
31:25 然后加黑
31:26 是表示我在精度上都比别人高啊
31:28 这个是那么几个数据集上面
31:30 基本上都是比前人高
31:32 然后我们再
31:33 回过头来
31:34 看一下我们之前讲过的 BERT 这篇文章
31:36 注意到这个论文就换成 bert 了
31:38 这个地方是 bert
31:39 可看到 bert 的Base
31:41 他用的是12层
31:43 他的维度也是768
31:45 所以 BERT base 就是为了跟 GPT 做对比的
31:49 虽然 BERT 用的是编码器
31:50 gpt 用的是解码器
31:52 编码器 在同样的层数啊和维度大小的时候
31:55 他比解码器其实那么简单一点点
31:57 因为他少一块不带掩码的那个模块
32:00 但是基本上你可以认为
32:01 他也是差不多等价的
32:02 所以 BERT base 作者就是为了跟 gpt 对比
32:05 然后你看 BERT 他的层数翻了一倍
32:08 然后他的宽度啊翻了1.3倍啊
32:11 然后最后你的 BERT Large 是你的
32:13 BERT base 的基本上复杂度是
32:15 差不多3倍的样子
32:17 那为什么你可以做三倍呢
32:18 是因为 BERT 用的数据集更大一些
32:21 这个地方讲的是 BERT 它用的数据集
32:23 它用了 GPT 的那个 BooksCorpus 的数据集
32:26 那就是他这个里使用的是词的个数
32:29 是用的8亿个词
32:31 然后他还用了一个基本上是3倍大
32:33 有20亿个词的 Wikipedia 的数据集
32:36 所以 对BERT的整个数据大小
32:38 基本上是 GPT 用的数据集的大概4倍的样子
32:41 所以他在这个数据集上
32:43 训练了一个比 gpt 大三倍的模型
32:45 那也是可以理解的
32:46 然后再回过头来看一下BERT的实验
32:49 这个地方比较了是 gpt
32:51 然后 BERT base
32:52 虽然跟你 GPT  的模型是差不多
32:54 但实际上在整个的平均的精度上
32:57 还是要比他好一点
32:58 你看他是75.1
32:59 那 BERT 做到了79
33:01 然后如果你把模型做更大的话
33:03 他还能从79.6提升到82.1
33:07 这也是对我们之前
33:08 讲过的 BERT 一个非常简单的回顾
33:11 好接下来我们来看一下 GPT 2
33:13 就当你发现你的工作被别人用
33:15 更大的模型
33:16 更大的数据打败的时候
33:18 那么你怎么样去回应 GPT 2这篇文章
33:21 它的标题啊叫做语言模型
33:24 是无监督的多任务学习器
33:28 我们等会来看
33:29 多任务学习器是什么意思
33:31 但无监督我们理解啊
33:33 语言模型我们理解
33:35 作者上一作没有变换
33:36 最后一个作者也没有变换
33:39 之前 gpt 那篇文章中间是有两个作者
33:42 现在全部换掉了
33:44 换成了四个作者
33:45 就是说主力干活的作者还是大老板也没有变
33:49 但是队员就换了一波
33:51 就在看摘要之前
33:53 大家想一想
33:54 如果你说我用一个解码器
33:56 训练一个很好的模型
33:58 效果非常好
33:59 觉得自己棒棒的
34:00 但是几个月之后被人用一个编码器
34:04 用一个更大的数据集
34:05 训练一个更大的模型打败了
34:07 那你心里怎么想
34:08 那你得打回去对吧
34:10 首先你不能换你的解码器了
34:12 因为你已经站好队了
34:14 如果你再换回编码器说编码器真的好
34:16 那么你前面的工作就浪费了
34:18 所以因为一作没有变
34:20 所以这个技术路线是不能变的
34:21 我还是要认为解码器好
34:23 那么怎么打回去呢
34:24 很简单我可以把我的模型做的更大
34:27 数据集做的更大
34:29 但如果我通过做更大
34:30 就能把前面的工作打败的话
34:32 那么我写文章也没什么问题
34:34 但问题是在于
34:36 如果你变大了
34:37 但是你还是打不赢
34:39 打你的那个工作的话
34:41 那么你怎么办呢
34:42 这就是 gpt 2 这个工作要面临的情况
34:45 我们可以大概看一下
34:46 首先他做了一个新的数据集
34:48 叫做 web text
34:50 然后有百万级别的文本
34:52 那么跟之前的 Wikipedia和 BooksCorpus 
34:55 那么当然这个数据集要更大了
34:57 你有了更大的数据级之后你能干嘛
34:59 那就可以训练一个更大的模型
35:01 15亿个参数的Transformer
35:04 记得 bert 的那只他最大只是3.4个亿
35:07 现在直接跳到了15亿
35:09 那就是说你的文本变成了百万级别的文本
35:12 那么你的模型变成了十亿级别的模型
35:15 但可惜的是说
35:16 当你变得那么大的情况下
35:17 你发现跟 bert 比可能优势并不大
35:20 这时候作者就找了另外一个观点
35:23 叫做 Zero-shot 的一个设定
35:25 他其实在 gpt 那篇文章的最后一节
35:28 有讲他用 Zero shot来做一些实验
35:31 主要是去了解整个模型的训练的基石
35:34 在 gpt 2这篇文章
35:35 就把 Zero shot作为他的一个主要的卖点
35:38 拿得出来
35:39 我们这篇文章主要看一下
35:40 是他怎么去卖
35:42 Zero shot这个事情呢
35:44 在导言里面
35:45 作者说 现在一个主流的途径就是对一个任务
35:49 收集一个数据集
35:51 然后在上面训练模型做预测
35:53 为什么这个东西很流行
35:54 是因为现在的模型
35:56 他的泛化性是不是很好的
35:59 就是说你在一个数据集一个应用上
36:01 训练好的模型
36:02 很难直接用到下一个模型上面
36:05 然后他又提到叫做多任务学习
36:08 多任务学习一开始的观点是说
36:10 我在训练一个模型的时候
36:12 同时看多个数据集
36:14 而且可能会通过多一个损失函数
36:16 来达到一个模式能够在多个任务上都能用
36:20 这个是在90年代末提出来的
36:22 在2000年到2010年之间啊
36:25 也曾经是比较流行的一个话题啊
36:27 作者说虽然这个东西看上去比较好
36:29 但是在 NLP 里面其实用的不多
36:32 在 NLP 里面
36:33 现在主流的算法
36:34 也就是之前 gpt1 和 bert 那一类的
36:38 就是说在一个比较大的数据上
36:40 做一个预训练的模型
36:41 然后在对每个任务上
36:43 做一个有监督的一个微调
36:45 当然这样子还是有两个问题啊
36:47 第一个是说对每一个下游的任务
36:50 你还是得去重新训练你的模型
36:52 第二个是说
36:53 你也得收集有标号的数据才行
36:55 这样导致你在
36:56 拓展到一个新的任务上是
36:57 还是有一定的成本的
36:59 然后导论的最后一段话就是说
37:01 GPT-2 要干什么事情
37:03 他说我还是在做我的语言模型
37:05 但是呢我在做到下游任务的时候
37:08 我会用一个叫做Zero-Shot的设定
37:11 Zero-Shot是说
37:12 我在做到下游的任务的时候
37:15 不需要下游任务的任何标注的信息
37:18 那么当然也不要去训练我的模型
37:21 这样子的好处说我只要训练一个模型
37:23 在任何地方都能用
37:25 最后一句话是说
37:26 我们得到了还看着挺不错的
37:28 而且有一定竞争力的结果
37:30 回到我们前面讨论的
37:32 如果作者就是在 gpt  1的基础上
37:35 用一个更大的数据集训练一个更大的模型
37:37 说我比 BERT 好一些
37:40 可能也就好那么一点点
37:41 不是好那么多的情况下
37:43 那么这篇文章有没有意思
37:45 大家会觉得没什么意思
37:47 工程味特别重
37:48 那么现在来了
37:50 我换一个角度
37:51 我选择一个更难的问题
37:54 我说做 zero Shot
37:56 就不训练不要下游任务的任何标号
37:59 然后跟你得到也还不错差不多的
38:02 有时候好一点有时候差一点的结果
38:04 虽然这个时候从结果上看没那么厉害
38:08 但新意度一下就来了对吧
38:10 所以这也给大家做研究有一些提示
38:13 你不要一条路走到黑
38:15 做工程你可以一条路走到黑
38:17 你就把精度往死里做
38:19 但是在做研究的时候
38:20 你一定要比较灵活一点
38:22 尝试从一个新的角度来看问题
38:24 接下来我们来看一下方法第二节
38:27 因为 gpt 2和 gpt 1在模型上
38:29 基本上是长得一样的
38:30 所以我们不给大家一段一段读了
38:32 而是给大家讲一下
38:34 跟之前方法的一些不同的地方
38:35 在什么地方
38:36 回忆一下我们在之前做 gpt 的时候
38:39 我们在预训练语言模型的时候
38:41 是在自然的文本上训练的
38:44 但是在做下游的任务的时候
38:46 我们对他的输入进行了构造
38:49 特别的是说我们加入了开始符
38:51 结束符和中间的分隔符
38:54 这些符号在之前模型是没有看过的
38:58 但是因为你有微调的环节
39:00 所以模型会去认识这些符号
39:02 你给我一些训练样本
39:04 我去认识这个符号代表什么意思
39:06 但现在你要做 Zero Shot
39:08 那你的问题是什么
39:09 你在做下游的任务时候
39:12 我的模型不能被调整了
39:14 但是如果你还
39:15 引入一些模型之前没见过的符号的话
39:17 模型就会感到很困惑
39:19 所以在这个设定下
39:21 我们在构造下游任务的输入的时候
39:24 就不能引入那些模型没有见过的符号
39:27 而是要使得整个下游任务他的输入啊
39:29 跟你之前
39:30 在预训练模型看到文本长得一样
39:33 就是说你的输入的形式
39:35 应该更像一个自然的语言
39:37 这个地方作者给了两个例子
39:39 第一个例子是说做机器翻译
39:41 如果你想把英语翻译成法语
39:44 你可以表达成这样一个句子首先是
39:47 翻译成法语
39:49 给你英语的那个文本
39:51 然后
39:51 接下来是你英语对应的法语的文本
39:54 所以前面这三个词啊
39:56 你可认为就是做了一个特殊的分割符的意思
39:59 在后面的文献里面这个叫做 prompt
40:02 也叫做提示
40:04 就如果你要做阅读理解的话呢他又说
40:07 我可以
40:08 设计一个提示叫做回答这个问题
40:12 接下来是你读的那个文本
40:13 然后是你的问题
40:15 最后是你的答案
40:16 这个地方
40:17 回答这个问题作为一个提示啊
40:19 模型知道哦
40:20 我现在要去做这个任务
40:22 接下来还有大段讨论
40:24 你为什么可以这么做
40:25 因为这个东西不是作者提出来
40:27 是前面的工作
40:28 这一篇工作提出来的东西
40:30 后面这些话基本上作者都在讨论
40:32 是说这个途径到底为什么可以工作
40:35 作者觉得如果你的模型足够强大
40:38 他能理解你那提示符干的事情
40:40 那当然就比较好
40:41 另外一个是说
40:42 这可能在文本里面
40:43 这样子的话也很常见
40:45 可能本来就出现在这里面
40:47 那么他在下面一节讲数据那一节
40:49 稍微对第二点做了一些解释
40:52 我们来看一下
40:52 他的训练数据长什么样子的
40:54 这一节里面
40:55 他详细讲了一下他的数据是怎么样出来的
40:58 首先第一段话是我前面的人
41:00 大家用啊 bert 用的Wikipedia
41:02 那么他们自己用的是书
41:04 那么接下来
41:04 你要构造一个更大的数据集才行
41:07 他说一个可行性的办法
41:08 需要一个叫做 Common Crawl的一个项目
41:11 Common Crawl是一个公开的网页抓取的项目
41:15 就有一群人写了一个爬虫
41:16 然后不断的去在网上抓取网页
41:19 然后把抓取的网页放在 aws 的 s3上面
41:24 然后供大家免费的下载
41:26 这个项目已经做了很多年
41:27 目前来说应该是有 tb 级的数量级
41:30 应该是目前能够很方便下到的
41:33 最大的一个文本数据集
41:35 作者说这个数据集不好用
41:36 这是因为他的信噪比比较低
41:38 因为抓回来的网页里面很多
41:41 可能是没有含有比较有意思信息的
41:43 可能就是一些很垃圾的网页
41:46 那么你要怎么去清理
41:47 他需要花很多很多的时间
41:49 就是说虽然我
41:50 没有能力现在把你很好的标出来
41:53 但是他可以去利用网上大家已经
41:55 过滤好的一些网页
41:57 具体来说他用的是 reddit
41:59 reddit 是一个美国
42:01 排名很靠前的一个新闻聚合网页
42:04 在国内好像没有类似的一个服务
42:07 他的想法是说每个人可以去提交
42:10 你感兴趣的一些网页
42:11 然后把你分门别类的放在每一个类别下面
42:15 接下来 reddit 的用户就是对你投票
42:18 说喜欢或者不喜欢
42:20 然后给他就进行评论
42:22 然后你投票的话
42:23 会产生一个叫做karma的一个东西
42:26 他最早来源于佛教里面的一个术语啊
42:30 当我不是专家
42:31 你大概可以理解成一个轮回报应值
42:34 在 reddit 上面
42:35 karma你可认为是用户对一个
42:37 帖子的一个评价
42:38 然后他选取了所有
42:40 至少有三个 karma 的帖子
42:42 reddit 的用户已经帮你读过
42:44 而且我觉得里面有一定的价值
42:46 然后他去把他所有的爬下来
42:49 最后得到了4,500万个链接
42:52 然后再把
42:53 他里面的文字信息给你抽取出来
42:55 就这样子得到了一个数据集
42:57 这个数据集最后大概是800万个文本
43:00 然后一共是40GBGB的文字
43:03 然后在表1
43:03 里面他又拎了一些句子出来证明说
43:07 其实在我爬下来的数据里面
43:09 就是对于英语翻法语这个例子来讲
43:12 已经有了很多的这样子的样例
43:14 比如说这句话是说有人写了
43:16 在法语里面写了一句这样子的话
43:18 然后如果翻译成英语来说
43:20 那就是长这样子啊
43:22 下面都是说
43:23 这些东西
43:24 都是怎么样对应的英语语句
43:26 翻译成法语长什么样子
43:28 作者想表达意思是说
43:29 如果你在这样子数据上面
43:31 训练语言模型的话
43:32 很有可能他确实就可以
43:35 真的把英语翻译成法语
43:36 因为你的文本里面
43:37 出现过很多这样子的例子
43:39 当你有了更大的数据级的时候
43:41 你当然可以把模型做了更大了
43:43 作者一共设计了四个模型
43:45 第一个模型有12层
43:47 每一层他的宽度是768
43:49 一共有1亿个可学习的变量
43:52 那么就是来自于之前的 gpt 或者 BERT Base
43:55 第二个模型就是 BERT large 了
43:58 然后他在之上啊
44:00 最大的情况下是说他
44:02 把层数再翻了一倍就是24
44:05 就是24变成了48
44:08 然后你的宽度啊也从1024变成了1600
44:11 基本上是1.5倍的样子
44:13 得到了一共有15亿个可学习元素的模型
44:17 就后面这些实验
44:18 我们就没打算给大家仔细的去过
44:21 因为他的实验啊
44:23 主要是跟别的做 Zero Shot的方法比 会长什么样子
44:27 比如说在这个地方
44:28 你看到了是他的这四个模型
44:32 跟当前在不同这些任务上面的 zero shot 的SOTA
44:36 他的方法的比较
44:37 这些方法
44:38 不是我们之前讲过的BERT那一类
44:41 而是说专门做Zero shot 那一类什么样
44:44 当然是说 gpt 我们比你们都好
44:46 因为你用到的模型
44:47 复杂度和数据量
44:48 确实比人家甩出几条街出来
44:50 那在最前面其实有一张表显示呢
44:53 是他在几个任务上面的一些体现
44:56 比如说这个是你的阅读理解
44:59 翻译摘要和问题回答
45:02 下面你的轴分别是你的模型大小
45:04 因为他这个地方有四个模型
45:06 所以他一共有4个点
45:07 然后这个地方你看到阅读理解上来说
45:09 他似乎跟别人还是不错的
45:12 就说这个是比较好的方法
45:13 摘要上面就差一点啊
45:15 这个是Seq2Seq
45:17 加上注意力机制的一个模型
45:19 还是差一点
45:20 如果你在 QA 上面
45:21 那就你跟现在的比较好模型差的远
45:23 因为现在比较好模型还在远远的上面
45:25 很远的地方了
45:26 所以你还早的很
45:27 所以就是说在摘要里面
45:30 作者说
45:30 虽然我们的结果还是比较有意思的
45:33 在一线任务上还做不错
45:35 另外一些任务上是有那么一点点意思
45:37 所以他讲的也是比较委婉了
45:39 但是注意到是说随着你的模型的增大
45:43 你的性能还是在上升的
45:46 也就是说你还是有希望
45:48 训练更大的模型
45:49 使用更大的数据集使得你的
45:51 模型的性能啊能够突破天际
45:53 使得跟真正的在有监督上面训练出来
45:56 效果是一样
45:57 这就是接下来工作 GPT-3要干的事情
46:00 这样 我们就快速的过了一下 gpt 2这篇文章
46:03 然后接下来我们来看 GPT-3这篇文章
46:05 GPT-3这篇文章的标题叫做语言模型
46:09 是 few Shot learner
46:11 在讲 GPT 的时候
46:12 我们有讲过他在文章的最后一段了
46:14 其实也做了一些实验
46:16 就是在此任务上面
46:17 我给你提供一些样本
46:19 但是不是在子任务上所有的样本的时候
46:22 其实语言模型能够用最少数的样本
46:24 能极大的提升性能
46:26 GPT  2是在 GPT  上往前走了一大步
46:29 是说在子任务上面
46:30 我不给你提供任何相关的训练样本
46:33 直接使用预训练模型
46:35 去对子任务上做预测
46:37 作者之所以这么做
46:38 很有可能就是为了跟 BERT 的文章
46:41 在新意度上能够有所区分
46:43 我们有讲过
46:44 一篇论文的价值取决于你的新意度
46:47 要乘以你的有效性
46:49 当然要乘以你问题的大小
46:50 但是不管是 gpt 还是 bert
46:52 他做的是同样的问题
46:53 所以问题的大小是固定的
46:55 gpt 2虽然在新意度上拉的特别高
46:58 但是有效性比较低
46:59 所以导致他论文的价值最后很难
47:02 说是一篇特别重要的文章
47:04 所以 GPT-3就是尝试去解决 gpt 2的有效性
47:08 所以他又回到了 gpt 一开始考虑的
47:11 few Shot设置
47:12 就是说我不再去追求很极致的
47:15 我在一个子任务上不给你任何样例
47:18 其实在现实生活中也很少
47:20 就算是人类你要学习的时候
47:22 你也要通过一些样本来学习
47:24 只是说人类在样本
47:26 的有效性上做的比较好
47:27 就通过一点点样本就行了
47:29 但是语言模型需要大量的样本
47:31 所以在这里 few shot的意思是说
47:34 我还是给你一些样本但不用太多
47:36 只要你的样本的个数是在可控的范围里面
47:39 所以这个成本还是非常低的
47:41 在作者上面
47:43 可以看到作者基本上换掉了啊
47:45 GPT 和 GPT2的一作已经跑到了最后
47:48 前面的这些作者
47:50 其实之前基本上是都没有出现过的
47:52 如果大家感兴趣的话
47:53 可以跳到文章的末尾
47:55 他有详细的解释的每个作者是干的什么事情的
47:59 我觉得GPT 3这篇文章的一大贡献
48:01 真的就是
48:02 虽然我挂了很多作者的名字
48:04 但是我还真
48:05 后面解释了每个作者干的什么事情
48:08 也是给大家一个标杆
48:09 说你可以写很多名字没关系
48:11 但是你至少告诉我说
48:12 这些人真的是干能活
48:14 哎不是 就是上面挂个名字来赚一个引用了
48:17 大家如果去仔细看的话
48:18 基本上看到前面这些做的
48:20 基本上都是在做实验的上面
48:22 GPT 3这篇文章
48:23 真的是做了特别特别多的实验
48:25 这也是整个 open ai 他做文章的一大特点
48:29 就如我们之前讲的 CLIP 文章
48:31 他也是做了大量的实验
48:33 所以导致有大量的作者
48:35 接下来我们来看一下摘要
48:37 摘要的前面几句话
48:38 没有什么特别好看的
48:40 就跟之前没有什么太多区别
48:42 具体来看呢
48:43 是说我们训练了一个 GPT 3的模型
48:46 这也是一个自回归模型
48:48 但是他有1,750亿个可学习的参数
48:54 比之前所有的那些非稀疏的模型
48:57 稀疏的模型 是说你整个权重可以是稀疏的
49:00 里面有大量的0
49:02 但如果你的模型有很多很多0的话
49:04 你把这些0算进去的话
49:05 你的模型也算的特别大 所以他作为对比啊
49:08 他跟那些非稀疏的
49:10 就是不会存在很多0的这些模型相比
49:13 他比他要大10倍
49:14 就是在可学习的参数上面
49:17 然后因为你的模型已经那么大了
49:19 那么在做子任务的时候
49:21 你如果还要去训练你的模型的话
49:23 那么你的成本上是很难的
49:25 所在这个地方
49:26 GPT-3在作用到指任务上面时候
49:30 不做任何的梯度更新或者是微调
49:33 就是就算是在 Few shot 的情况下
49:36 给你一些样本情况下
49:38 GPT-3也不是用微调
49:40 因为因为微调需要你总是去算梯度
49:43 那么大的模型
49:44 算梯度是非常非常难的事情
49:46 所以这个地方
49:46 他是不做任何的梯度更新的
49:48 也是他的一大特点
49:50 然后他说我在
49:52 所有的这些 NLP 的任务上取得了很好的成绩
49:56 这也是跟 GPT 2他能区分开来
49:59 GPT 2 他的成绩跟我们想要的还差得很远
50:02 然后最后作者说 GPT 3能生成一些
50:05 新闻的文章
50:07 而且人类读起来是很难区分
50:09 看来你到底是模型生成的
50:11 还是人类写的
50:12 这也是 GPT  3的一大卖点
50:14 也就是后面大家能通过他
50:17 玩出花样来的一个主要的地方
50:19 在这个地方还有这就是摘要
50:21 就是说 GPT  3特别大
50:23 在做子任务的时候不需要算梯度
50:25 这是因为他特别大
50:26 而且他的性能特别好
50:28 这是他想要表达的东西
50:30 接下来是他的目录
50:31 这也是我们第一次读到
50:33 在论文的第二页放目录的文章了
50:36 然后可以看到前面两节是讲他的方法写了10页
50:40 然后是他一个长长的结果
50:42 他又写了10页
50:43 在后面是一个长达20页的一个讨论
50:47 在讨论之后还有一个20页的附录
50:50 里面讲的是一些细节
50:52 所以整个文章有63页
50:54 他不是一篇投稿的文章
50:56 而是一个技术报告
50:58 所谓的技术报告是讲没有发表的文章
51:01 因为他没有板面啊和页数的限制
51:03 你可以写的特别长
51:05 当然长有长的好处啊
51:06 他可以把东西写的特别细
51:08 所以你在读他的时候
51:09 可能没有相关的背景知识
51:11 读起来也没问题
51:12 但是长的坏处是说
51:14 你的阅读门槛又增加了
51:16 如果我就想了解一下
51:17 你做什么事情我要读63页
51:19 那我怎么读
51:20 但这个地方我的个人看法是
51:22 GPT-3真的没必要写那么长
51:24 他写那么长
51:25 他并没有把前面的东西
51:27 交代的特别详细
51:29 也就是为什么我们在讲 GPT-3之前
51:31 需要给大家讲一下什么是 gpt 和 GPT  2
51:34 因为这两篇文章的内容
51:36 在 GPT-3这篇文章里面是没有覆盖的
51:38 就是说虽然我写了63页
51:40 但我并没有讲前面两个工作什么东西
51:43 而且GPT-3是完全基于 gpt 2这个模型的
51:46 63页并没有讲这个模型
51:48 而是他花了大量的篇幅去想着
51:51 结果啊和后面那些讨论
51:53 所以导致说在读这个63页的论文之前
51:56 我们先得把前面两个论文给读了才行
51:58 所以我个人是非常不推荐
52:00 大家这种写法啊
52:02 你要么就写的短一点
52:03 大家读下来很快就知道你的中心思想
52:06 要么你就写的长一点
52:07 把前面的背景知识
52:09 给大家详细的介绍一下
52:11 我不需要读前面的文章
52:12 从你这篇文章开始
52:13 我也能知道你在做什么
52:15 像这种你既需要读前面文章
52:18 又需要读我很长的文章
52:19 只有当你的工作是真的是特别特别好的时候
52:22 你才可以那么任性
52:24 别人才会来读你的文章了
52:25 我们接下来看一下导言
52:28 导言的第一段还是说最近一些年来啊
52:30 NLP 里面 大家都使用预训练好的语言模型
52:33 然后再做微调
52:35 第二段话是说这当然是有问题的
52:37 他什么问题呢
52:38 他说我们对每个子任务
52:40 我还是需要一个跟任务相关的数据集
52:43 而且呢要跟你任务相关的一个微调
52:47 具体来说他列了三个问题
52:49 第一个问题是说
52:51 你需要一个大的数据集
52:52 你得去标号吧
52:53 这当然是有问题的
52:55 GPT-2也讲到这个事情了
52:56 第二个我觉得就相对来说比较虚一点
53:00 就是说当你的一个样本
53:02 没有出现在你的数据分布里面的时候
53:04 你泛化性
53:05 不见得就比你那个小模型要好
53:08 所以是说
53:08 如果你在微调上面的效果很好的话
53:12 也不能说明你的预训练的模型
53:15 他的泛化性就特别好
53:16 他很有可能就是你过拟合你的
53:19 预训练的训练数据
53:21 而且这个训练数据跟你的微调
53:23 所要的那些任务啊
53:24 刚好有一定的重合性
53:26 导致你在这些微调任务上
53:28 是做的比较好的
53:29 就跟之前用书来做预训练
53:31 用Wikipedia做预训练
53:33 或者是在往上爬的网页做预训练
53:35 这些文字里面
53:36 刚好包括你所有下游任务
53:39 他要的那些文字
53:40 他们都是
53:41 类似的一些文字
53:42 所以导致你的微调效果比较好
53:44 但是如果你换到一个别的语种啊
53:47 或者换到一个更专业性的文本上面
53:49 你的表现力可能就不那么的好了
53:51 所以作者在这里的意思是说
53:53 假设我不允许你做微调
53:55 不允许你改变你预训练模型的参数的话
53:58 那么你就是真的就是拼的
53:59 预训练模型的泛化性
54:01 假设我允许你微调的话
54:03 那么预训练模型可能好一点坏一点
54:05 他都差别不那么大了
54:07 第三个是说人类啊
54:08 大家都会说到人类
54:09 人类不需要一个
54:11 很大的数据集来做一个任务啊
54:13 就是说你有一定的语文功底的话
54:15 我让你做一个别的事情
54:16 你可能给你两个例子
54:18 告诉你怎么做就行了
54:19 你不需要再采集成件上万
54:22 就你不要做个几本习题题
54:23 才会掌握一个小应用了
54:25 然后作者提出这个问题之后
54:27 要讲他的解决方案
54:29 他的解决方案也跟之前讲过
54:30 他其实也就是做
54:32 few Shot或Zero Shot的学习了
54:34 在这个地方呢作者呢
54:36 他又换了一个名词来了
54:38 他说一个解决这个问题的办法
54:41 叫做Meta -Learning
54:44 叫做元学习
54:45 我觉得作者在取名字这个事情上
54:48 也不见得是那么的精确
54:51 就是跟 gpt 2用的是 multi task 多任务学习
54:55 但是他其实跟
54:56 之前的 Multi Task learning
54:58 还是有那么一点点区别的
55:00 然后在这个地方
55:01 他又试图去重新定义
55:03 什么叫做Meta-Learning
55:06 他有一个注释啊
55:07 有个长长的注释讲的说啊
55:08 他我们跟之前大家
55:10 叫的Meta-Learning当然是有一点的不一样了
55:12 所以这个地方我们有我们自己的定义
55:14 但我觉得
55:15 你如果想重载前面大家都知道的一些名字的话
55:21 除非有特别多的必要啊不然没意义
55:24 因为你会给大家造成误解
55:26 而且 大家现在讲到 GPT 3这边文章的时候
55:29 也不会去提 他是用的是Meta-Learning
55:32 或者是他是用的是 Multi Task learning
55:34 然后他当然在后面又定了一个名字
55:37 叫做 in Contex learning
55:39 就是在有上下文之间的学习
55:41 虽然用的是 zero Shot、Few Shot
55:44 他在这个地方在 摘要 上面已经讲过
55:46 我是不更新我的模型了
55:49 因为在
55:49 计算机视觉里面我们有讲Zero Shot
55:51 Zero Shot好理解
55:52 那我什么都不干没关系
55:54 但是作为 few Shot的话
55:56 我给你一些样本的话
55:57 我还是可以用这些样本来
55:58 对我的模型继续更新
56:00 这样子我能够更拟合到这个上面去
56:03 他这个地方他强调的是
56:05 我不要对我的权重做任何的更新
56:07 因为你的模型太大了更新不了
56:10 所以呢
56:10 他这个地方要需要跟前面做区分开来
56:13 所以他尝试的
56:14 用了两个名词的这个地方
56:16 一个是Meta-Learning一个是in context learning
56:19 但是大家理解一下他想什么就行了
56:21 所谓的Meta-Learning
56:22 就是我真的训练一个很大的模型
56:24 里面的泛化性还不错
56:26 in coneax learning 是说我在后面的时候
56:29 即使告诉我一些训练样本
56:31 我也不更新我的权重
56:32 他在前面有画一个图啊
56:34 就是图1上面有讲了一下
56:35 Meta-Learning的大概一个想法
56:37 他这个地方
56:38 画的是有一点点的奇怪的啊
56:40 他看上去好像是讲
56:41 我的模型是怎么训练的
56:43 就是说我有一个通过 sgd
56:45 来做预训练的过程
56:47 然后呢在每一步里面
56:49 好像要做一个什么样的事情
56:51 他其实他不是真正的讲
56:52 GPT  3这个模型怎么训练出来的
56:55 而是说这个语言模型呢
56:57 你可以怎么样类比成一个Meta-Learning呢
57:00 他是说如果你这一个是一个样本
57:02 这也是一个样本
57:03 而且每个样本来最不同的文章的时候
57:07 可能他要干的事情不一样
57:09 比如说这一个样本有这一段话
57:11 告诉你的是各种加法怎么做
57:14 下面的话告诉你是一个错别字
57:17 怎么样改成一个正确的
57:18 然后再后面就是英语翻成法语
57:21 所以说在每一个段落或者每一个文章
57:24 如果来自很不一样的地方的时候
57:26 他可能教你不一样的东西
57:28 如果你在大量的这种
57:30 很多样性的文章上做训练的时候
57:32 你的模型
57:33 多多少少有在做一个元学习的过程
57:36 就是他学习的大量的任务
57:38 而且每一个段落
57:39 你可以认为是一个叫上下文的学习
57:41 因为他们之间是相关的
57:44 然后你要从上下文来得到一些信息
57:46 但是他们之间呢他就没有太多关系了
57:48 就是多个任务之间了
57:50 所以这个东西放在这里啊
57:51 其实放不放
57:52 我觉得他都不影响到他的模型的啊
57:55 但是放在这里我们就讲一下
57:56 但是大家如果一开始读的时候
57:58 读的有点奇怪啊
58:00 可以忽略不要紧
58:02 然后再讲了他的设定之后
58:03 他又说最近些年啊
58:05 大家的模型的大小变得越来越大
58:07 但是其实我觉得也就是 open ai
58:10 把整个军备竞赛给大家搞了起来
58:12 像 gpt3 一出来大家都觉得哇
58:15 你可以做那么大
58:15 然后别的公司也纷纷的跟进
58:18 不管是美国的还是国内的公司
58:20 大家也愿意去参加这样子的比赛
58:23 然后在后面也是说
58:24 GPT-3是一个1750亿个可学习参数的模型
58:29 然后他的模型
58:30 他的评估是用了这三个办法
58:32 一个叫做 FewShot Learning
58:34 也就是说对每个子任务啊
58:36 我给你提供大概10-100个的训练样本
58:40 那么他的一个特殊的情况
58:41 叫做One Shot的案例
58:43 就是每一个任务我只给你一个样本
58:45 就是说英文翻法语的时候
58:47 我就告诉你一个
58:48 英文 hello word 怎么翻成法语的那一个词
58:51 然后让你接下来给我继续翻下去
58:53 那么接下来是 zero Shot
58:54 就是说我一个样本都不告诉你
58:56 我就让你英语翻法语
58:58 然后他在一开始啊给大家的一张图
59:00 给大家展示了一下
59:02 在三个设定下他的模型的一个区别
59:06 他的 x 轴在这个地方
59:07 是整个语言模型课学习参数的大小
59:11 啊这1.3 B基本上就是 GPT 2的模型
59:15 然后你的 y 轴是你的 accuracy
59:17 当然你在很多
59:19 子任务上面他做了一个平均
59:20 就是这些虚线是每一个子任务上的
59:23 然后他做平均就变成了三个实线
59:26 然后这里有三条线颜色不一样的线
59:28 黄色表示的是 few shot
59:30 绿色表示的是 one shot
59:32 蓝色表示的是 zero shot
59:34 之前我们讲过的 GPT 2这篇文章
59:36 你可以认为就是1.3 b 这个模型
59:38 然后用 Zero Shot
59:39 那么精度可以认为是
59:40 平均下来是30%左右的样子
59:42 然后你把1.3 b 变成了175 b 的时候啊
59:46 就这个点的时候
59:47 而且使用了 Few shot 就允许给你
59:50 10-100个的样本的时候
59:52 那么基本上看到他的精度接近了60%啊
59:56 就是基本上你的精度翻了一倍了
59:58 所以可以看到效果还是非常明显的
60:01 好这就是他的导言
60:02 接下来我们来看一下第二章
60:04 也就是他的模型的部分
60:06 在模型的部分呢
60:07 他先给大家又重新讲了一下
60:09 什么叫做Fine tuning
60:10 然后他的 few Shot learning
60:12 和他 one Shot
60:14 以及他的 Zero  Shot他到底是什么区别
60:16 但其实你在这个地方
60:17 你可以通过下面这个图啊
60:19 是看的比较清楚的
60:21 首先右边讲的是微调是怎么做的
60:24 在微调的时候
60:24 我们训练好预训的模型之后
60:27 在每一个任务上面
60:28 我们提供一些训练样本
60:30 然后这个地方
60:30 假设我使用批量大小为1来训练的话
60:33 就每次给你一个样本
60:35 这个是英语翻法语的样本
60:37 因为我有标号所以我能计算损失
60:39 然后我就可以去对他的权重进行更新
60:43 再拿到一个新的样本继续更新
60:45 就可以当做一个很正常的
60:46 训练任务来做
60:47 但是跟之前不一样的是说
60:49 微调通常对数据量的要求要
60:51 少于从0开始训练
60:53 而且在学习率上
60:54 通常可以做的比较小一点
60:56 这是因为微调的初始值啊
60:59 那个模型是用预训练好的模型做的
61:01 所以他跟你最终的解 已经很近了
61:04 所以你只要大概稍微调一下就行了
61:06 但是在 gpt 3模型的设置里面
61:08 他追求的是不做梯度更新
61:10 当不做模型更新
61:11 他肯定是有他的新意度的
61:13 反过来讲
61:14 那么大一个模型
61:15 假设换了一个新任务上
61:17 还得再做更新的话
61:19 那么他的使用门槛是比较高
61:21 所以也不可能使得像现在那样
61:23 大家可以在 GPT-3上面玩出花来
61:26 他这里使用的是英语翻法语这个例子
61:29 他想干的事情是说把英语的Cheese
61:32 翻成法语的 对应的单词
61:34 假设在Zero Shot里面怎么办
61:36 他就在前面加一句说把英语翻成法语 然后冒号
61:40 这是你这个任务的描述
61:42 当然 他希望你预训练好的 GPT-3模型
61:45 有理解这句话是想干什么事情
61:46 然后是把我要翻译的词放进来
61:49 加一个箭头
61:51 箭头这个东西叫做 prompt 也叫做提示
61:53 告诉你这个模型说好
61:55 接下来就是轮到你输出了
61:57 然后把这句话放进模型
61:58 模型对下一个词的预测
62:00 这个词那就应该是Cheese
62:02 对应的法语的单词
62:03 如果你对了那就是对了
62:05 如果错了那就是你模型预测错误
62:07 如果需要 one shot 怎么做呢
62:09 就是在你任务描述之后
62:11 和在你真正的做翻译之前
62:14 我插一个样本进来
62:16 就是在定义好这个任务之后
62:18 我再告诉你一个例子
62:20 英语单词翻成法语单词
62:21 应该是这么翻译的
62:23 就希望你的模型在
62:25 看到整个句子的时候
62:26 能够从这条里面提取出
62:28 有用的信息来帮助你做后面的翻译
62:31 注意到这一点是说
62:33 这是一个样本放进去的
62:35 他只是做预测
62:36 他不做训练
62:37 就说虽然他是一个训练样本
62:39 但是他放进之后是不会对模型算梯度
62:43 也不会对模型做更新
62:44 所以他希望的是你在模型在做
62:48 前向推理的时候
62:50 能够通过注意力机制
62:52 然后去处理比较长的序列信息
62:54 从而从中间抽取出来有用的信息
62:57 能够帮助你下面做事情
62:59 这也是为什么叫做上下文的学习
63:01 是你的学习只是限于你的上下文
63:04 那么 few shot 的能力呢
63:05 就是对One shot 的一个拓展了
63:08 就之前我是给你一个样本
63:09 现在我会给你多个样本
63:11 当你可以做更长
63:12 但是更长不一定有用
63:14 因为你这个模型
63:15 不一定能处理特别特别长的
63:18 数据 就说如果你的序列很长的话
63:21 那么模型也不一定有能力把整个
63:23 句子里面的信息给你抽取出来
63:25 然后让你帮助到生成做这个事情
63:27 所以看完这个图之后
63:28 大家就知道这两种模式之间的区别
63:31 GPT 3采用了这个系列
63:33 当然是对新的任务更加友好了
63:35 就说我 碰到一个完全之前没见过的任务的话
63:38 我不要去更新我的模型
63:40 因为做模型的推理和做模型的训练
63:43 在你的设置上是很不一样的
63:46 因为在训练的时候
63:47 我对内存的要求更高
63:49 而且有超参数要调
63:50 而且得很好的准备你的训练数据
63:53 但现在我只要做预测就行了
63:55 来个新任务给你
63:57 你把结果返回给我就行了
63:59 这当然是他的好处
64:00 也有一点的坏处啊 坏处是说
64:02 假设我真的有很多训练样本那怎么办
64:06 比如说我就做英语到法语的翻译
64:08 大家很容易在网上找到个几百上千个样本来帮助你翻译
64:11 对吧这个时候你发现
64:13 你想放进去是很难的一件事情
64:15 你难道你要构造个样本里面
64:17 把整个子任务的训练数据放进去吗
64:20 那么就是特别长你可能模型处理不了
64:22 第二个问题还是相关的
64:24 就是说 我假设有一个还不错的训练样本
64:27 然后你的模型呢
64:28 在不给你的训练样本时候表现不行
64:30 我需要给你个训练样本
64:31 但是每一次我都给你
64:33 就每一次做一个新的预测的时候
64:35 我都把你给你
64:36 因为你这个模型是
64:38 每一次的时候
64:38 要从中间去抓取有用的信息
64:40 就我不能把
64:41 上一次模型从中间抓取的信息
64:44 给你存下来
64:45 存到你这模型里面
64:46 所以这也导致说
64:47 虽然 GPT-3
64:48 在一年半前就把这个效果做的那么好
64:51 但实际上好像用 FewShot 做这种
64:53 上下文的学习
64:55 似乎用的还不那么的多
64:57 2.1节讲的是他的模型和架构
65:01 他说 GPT 3的模型跟 GPT 2的模型是一样的
65:04 后面补充了
65:05 GPT 2模型跟之前 GPT 的区别
65:07 是你的模型的初始改变了啊
65:09 把你的Normalization放到了前面呢
65:11 和可以反转的词元
65:13 是也做了一点的改动
65:15 具体来说
65:15 他就是把 Sparse Transformer 这个工作啊
65:18 里面的那些改动给你拿了过来
65:20 然后他设计了8个不同大小的模型
65:24 具体来说会看在表2.1里面讲了
65:27 这个表里面每一行表示的是一个模型
65:31 每个列能表示的是模型的一些参数
65:33 比如说这个列表示的是
65:35 你模型里面有多少个可以学习的参数
65:37 然后你的模型里面有多少层
65:39 然后你每一层呢
65:41 你那个词表示成一个多么长的向量
65:44 以及在多头注意力里面有多少个头
65:46 就是你每个头的那一个维度的大小
65:49 他就是等于你这个d model 除以你 n heads
65:53 Batch size 是说在训练的时候
65:55 每一个小批量大小多大
65:57 最后是你在训练的时候
65:59 用的学习率是多少
66:00 首先看一下第一个模型啊
66:02 第一个模型是 GPT  3 Small
66:04 可以看到他12层
66:05 每一层大小是768
66:07 是不是很熟悉
66:08 他就是 gpt 模型
66:10 他的参数是这样子的
66:11 然后他的可学习参数是1.25个亿
66:14 也是 BERT Base 他的模型的大小
66:17 GPT-3 medium
66:19 24层每一层大小是1024
66:22 然后大家知道
66:23 这个尺寸是 BERT large 的尺寸
66:26 然后在后面这个模型呢
66:27 就是层数没有变
66:28 但是你每一层的那个宽度有增加
66:31 然后看到1.3 b 这个模型啊
66:33 虽然之前我们在讲图2的时候
66:35 讲到这个结果时候
66:36 我们说这个结果大概等价于
66:38 gpt 2的模型
66:39 gpt 2的大小是1.5 b
66:41 但实际上他的
66:42 大小是跟 gpt 2是不一样的
66:44 gpt 2在这个地方其实他有48层
66:47 但是他的模型呢宽度是要窄一些
66:50 所以 GPT-3 xl 跟 gpt 2比他是要浅一些
66:55 然后要宽一些
66:56 然后他一直增加
66:58 增加到最后就是 gpd3 175 b
67:01 或也简称是 GPT  3这个模型的话
67:04 他用的是96层
67:06 然后每一层的大小
67:08 已经到了一万二千的左右了
67:10 所以这个已经是非常
67:11 非常大的一个尺寸了
67:13 然后大家可能会问
67:14 这些参数怎么样定出来的
67:16 我觉得这个可能是作者拍拍脑袋吧
67:19 但我们知道
67:20 就是说你把你层数增加的时候呢
67:22 你的宽度也应该增加
67:24 我们知道把层数增加的时候
67:26 你的宽度也要对应的增加
67:29 因为你的计算复杂度
67:30 跟你的宽度是平方关系
67:31 跟层数是线性关系
67:33 但整体来说
67:34 GPT-3的模型是比较偏扁一点的
67:36 比如说 GPT-3最大的模型
67:38 跟前面比那就是16倍的大小关系
67:41 但是在96这个层数上呢
67:43 其实跟前面比
67:44 也就是最终是8倍的关系了
67:46 然后看到批量的大小在大小可以看到
67:49 当你训练很大的模型的
67:51 他用的是3.2个Million
67:53 也就是说你一个小批量里面有320万个样本
67:57 这是一个非常巨大的一个批量大小了
68:01 这个对你内存的考验是非常大的
68:03 因为你在计算的时候
68:05 因为你在计算梯度的时候
68:06 你中间变量的那一个大小是
68:09 跟你的批量大小成正比关系的
68:12 当然在分布式的情况下
68:13 假设你在机器与机器之间用的是
68:16 数据并行的话
68:17 那么你每台机器要计算的批量大小
68:19 应该就是320万除以你机器数量的大小
68:22 所以如果你有很多台机器的话
68:24 你 100或上千台机器的话
68:26 每台机器也还是能撑住的
68:29 作者有提到
68:29 你为什么要用相对来说比较大的批量大小
68:32 因为你批量大小一大的话
68:34 你的计算性能会好
68:35 就每台机器的并行度更高
68:37 而且你的通讯量也变低
68:38 所以分布式是比较好的
68:40 之所以你在小的模型
68:41 你不用很大的批量大小
68:43 是因为 对小的模型其实是更容易过拟合一些
68:47 就是你需要用一个相对来说
68:49 比较小的批量的大小
68:50 这样子导致你在采样的时候
68:52 数据里面噪音是比较多的
68:54 然后你当你的模型变得很大的时候
68:56 你相对来说用大的批量大小
68:58 你降低了批量里面的噪音
69:00 好像对大的模型来说
69:01 问题不是那么的大
69:03 这有一点点反直觉啊
69:04 这一块其实最近有很多工作去研究
69:07 为什么这么回事
69:08 当你的模型变得越来越大的时候
69:10 似乎你的过拟合没有那么的严重
69:12 大家怀疑有两个原因啊
69:14 一个原因是说你神经网络他
69:15 背后这么设计下来
69:17 大家训练出来能得到比较好结果
69:19 其实背后有一定的结构
69:22 使得他不那么容易
69:23 就像简单的 mlp 一样
69:25 直接的这么那么过拟合了
69:28 第二个是说
69:28 当你的模型变得越来越大的情况下
69:31 而且在有结构的情况下
69:32 他能收得了范围更广
69:35 而且这样就更有可能去概括到一个
69:38 可能存在的一个比较简单的一个模型架构
69:41 如果你的模型比较小的话
69:42 你可能搜索空间都
69:43 搜不到那一个简单的模型那边去
69:46 当你模型很大的时候
69:47 那你的 SGD能够帮助你去找到那一个模型
69:50 最后导致你的泛化精度比较好
69:52 当然都都是一些猜想啊
69:53 大家有在做研究工作
69:55 我们在这里就不展开给大家讲了
69:57 最后学习率啊
69:58 学习率 他就是当你批量大小变大的时候
70:01 你的学习率他是往下减的
70:03 这个其实也是跟之前的一些工作
70:06 他的结论是相悖论的啊
70:09 之前 facebook 的一个工作是说
70:11 当你的批量大小往上增的时候
70:13 你的学习率要线性的往上增
70:15 但这个地方他其实是一个反过来的
70:17 他学习的往下降
70:18 作者在段落中有提到
70:20 为什么他是要往上增和往下降啊
70:23 大家可以去看一下他
70:24 文章里面提到的原始论文里面的解释
70:27 反过头来看2.1章啊
70:29 他真的就是比较短小的
70:30 就是两段话就解决了
70:32 也就半页的样子
70:33 就是说在一篇63页的文章里面
70:36 整个模型的架构就写了不到半页
70:39 而且这个地方你根本就没写清楚
70:41 是说我的模型跟 gpt 2是一样的啊
70:44 那么你得去看一下 gpt 2
70:45 然后说我在上面又做了一些改进呀
70:48 用了一个叫 sparse transformer 的结构
70:50 你得也去看这篇文章
70:51 然后这个地方还提了一句
70:53 说 GPT2其实跟 GPT1是改了这些东西
70:56 就导致说你作为一个读者的话
70:58 你想搞清楚 GPT-3
70:59 整个模型长什么样的话
71:01 你得去读一系列的参考文献
71:03 当你这篇文章已经有63页的情况下
71:06 我觉得这么做是没有那么的必要性的
71:09 你在这个地方就给大家讲一下 gpt 2
71:11 模型长什么样子
71:12 甚至是 gpt 模型长什么样子
71:14 以及说你这个 spaster transformers
71:16 长什么样子
71:17 你就算是放在一个相关工作里面
71:20 或者放在后面都是可以的
71:22 因为这样的话
71:23 会给没有读过之前那些文章的
71:25 读者带来很大的便利
71:27 这是因为你去读前面工作的话
71:29 你还得把他的完整的故事读一遍对吧
71:31 他的记号用的是什么
71:33 他的这些表达是什么样子
71:35 然后我们已经读到这个地方了
71:37 用所有的标号啊
71:38 整个写作风格我们已经读下来
71:40 是比较熟悉了
71:42 如果你在这个地方写清楚
71:43 或者甚至是你在后面的附录写清楚
71:46 那我也不需要重新再读一个新的故事
71:49 而是直接知道这个技术
71:50 细节长什么样就行了
71:52 也符合这篇文章要卖的
71:53 就是上下文的学习
71:55 当然我们这不是要
71:56 批评这篇文章写的不好啊
71:57 只是给大家指出来
71:58 说读这篇文章上遇到这样子一些障碍
72:01 大家自己在写作时候
72:03 可以想办法去避免这样子的事情
72:06 第2.2节讲的是他的训练的数据
72:09 当你要做一个很大的模型的时候
72:11 当你的训练数据就得非常大了
72:13 这个地方
72:13 他们的训练数据是基于 common Crawl
72:16 在 GPT  2这篇文章里面
72:18 他有提到说我们可以考虑 common Crawl
72:20 但是他觉得 common Crawl 里面的数据太脏了
72:23 用起来比较难 
72:24 所以他采用的是另外一个办法
72:26 在这个地方
72:27 如果你想训练一个比
72:28 GPT2要达100倍的模型的话
72:30 那他得不得不去
72:31 重新去考虑 common Crawl这个数据了
72:34 具体来说
72:34 他做了三个步骤来
72:36 使的这个数据让他变得更干净
72:38 首先他们过滤了一个版本
72:41 然后是基于他的
72:43 相似性和一个更高的一个数据集
72:46 具体来说他干了什么事情呢
72:48 啊大家回忆一下
72:48 在 GPT  2里面他把 reddit 的上面爬下来
72:52 然后把 Karmma大于3的那些帖子
72:54 给你下载下来
72:55 作为一个高质量的网络数据集
72:58 那这个地方他干的事情就是说
73:00 把 common Crawl 下下来
73:01 然后呢把他的样本作为负例
73:04 然后之前 gpt 2那个网页数据集啊
73:06 作为正例
73:07 那个是高质量的 common Crawl
73:09 你认为大部分是低质量的
73:11 然后在上面做了一个很简单的
73:12 Logistic Regression 做一个二分类
73:14 正类是 gpt 2的爬下来的数据集
73:17 负类是 common Crawl 里面的
73:19 那么接下来做预测
73:21 对 common Crawl 里面所有的网页拿出来
73:23 如果分类器认为你是偏正类的话
73:26 就说你的质量比较高的话
73:28 那么他就留下来如果是
73:29 如果是判断出来很负类的话
73:31 那么就是过滤掉
73:33 第二个是他做了一个去重的过程
73:36 就是说如果一篇文章跟另外一篇文章很相似的话
73:39 那我们就把这篇文章去掉
73:41 他具体用到的是一个叫做 lsh 的算法
73:44 他可以很快的判断一个集合
73:47 一篇文章是一个集合
73:48 就是一些词的集合
73:49 和另外一个
73:51 很大的一个集合之间的相似度
73:53 这个在Information Retrieval里面
73:55 是一个非常常用的技术
73:56 如果大家不熟悉的话可以去看一下
73:58 这也是在面试中间
74:00 大家很喜欢问的一类问题
74:02 第三个是说我们又加了一些
74:04 已知的高质量的数据集
74:05 就是把之前的BERT 
74:07 gpt 2啊 gpt 的所有数据都拿 过来也加进来
74:10 最后就得到一个
74:12 非常大的一个数据集了
74:13 可以看一下在放在下面这个地方
74:16 首先第一行就是 common Crawl 
74:17 就是他们新加进来的数据
74:19 这里面一共有4万亿个字
74:22 web text 就是 GPT 2用的数据集
74:25 它上面一个比下面一个大20倍的样子啊
74:28 但是它的模型已经大了100倍啊
74:30 然后接下来是书的数据集和 Wikipedia
74:33 就虽然 common Crawl 里面给你带来了大量的数据
74:36 但是作者认为它里面
74:37 质量还是相对来说比较差的
74:39 所以在采样的时候
74:40 他是用了稍微不一样的采样率
74:43 虽然 common Crawl  你比后面这些
74:45 加起来还要大那么7、8倍的样子
74:48 但是在采样的时候
74:50 也是说一个 批量大小 一个一百万大小的批量里面
74:53 也就是60%的数据是来自common Crawl 
74:57 有 22%的数据是来自于 Web text 2 的
75:01 就你可以看到
75:01 common Crawl 里面的数据也就比下一个多3倍
75:04 虽然你的大小上来时候多了20倍
75:07 而且下面这些 Wikipedia
75:08 虽然他的大小比你上面要小很多很多
75:11 但是他的权重并不低
75:13 也就是导致说在采样的时候
75:15 他大量的采样的 Wikipedia
75:17 Books1和 web text 2的数据
75:19 这样子保证你这个小批量里面
75:21 有大部分的数据
75:22 他其实的质量还是很高的
75:25 具体来说这个权重怎么来的
75:26 好像作者也没有解释的那么清楚了
75:29 2.3是一个非常短小的段落
75:32 来讲整个模型是怎么训练的啊
75:34 这个又是这篇文章不那么"厚道"的一个地方
75:36 GPT-3这个模型是非常难训练的
75:39 要想他有接近
75:40 2,000亿个可以学习的参数
75:41 整个模型是非常大的
75:44 你训练他的话当然需要分布式训练
75:46 然后你需要做非常好的模型分割
75:48 和数据分割
75:50 然后他说他是在一个 v 100的
75:53 有的带宽很高的集群上训练的
75:55 这个集群来自于微软
75:57 那实际上说他用的是DGX-1 的一个集群
76:02 那里面的带宽是非常非常高的
76:04 一般的人是买不起
76:06 所以他就一句话就带过了
76:08 虽然他说我在
76:09 附录B里面有讲这些东西
76:11 实际上他也没讲什么东西
76:12 就讲了一些超参数是怎么训练的
76:14 这一块啊
76:15 如果要真的讲的话
76:16 其实有很多很多东西可以说
76:18 2.4节是讲模型的评估
76:21 跟之前不一样
76:21 因为这个地方他不需要做微调
76:23 所以他不需要一个额外的章节是说
76:25 微调是怎么做的
76:26 而是说我预训练模型好了
76:28 就 我就直接对他进行评估
76:30 在评估的时候
76:30 他用的是上下文的学习啊
76:33 具体来说他在每个下游的任务里面
76:35 他的训练集里面
76:36 采样 k 个样本作为你的条件
76:39 但 k 可以等于0啊1啊或者10到100
76:42 然后他的 prompt 用的是 Answer：
76:45 或者 A：
76:46 比如说我要做分类的时候
76:49 比如说那么我就把
76:50 几个样本采样出来放在前面
76:52 你在前面加一个我要干什么事情
76:54 如果你是二分类的话
76:56 那么你的答案要么是 True 要么是 False
76:58 而不是说一个0或1
77:00 因为0或1在训练数据中出现的概率没了
77:03 True 和 False 那么高
77:05 接下来 如果你的答案是一个自由的形式的话
77:08 比如说我在做问答的时候
77:10 假设你的答案是要
77:12 真的给我回答
77:13 一个自己编出来答案的话
77:14 那么他就采用的是Beam Search
77:17 就是跟机器翻译一样啊
77:18 我生成一个序列出来
77:20 然后用Beam Search就找到一个比较好答案
77:22 所以到这里
77:23 他就讲完了他整个模型的部分
77:26 可以看到 虽然到这个地方已经有实验的样子
77:28 但实际上他真正的讲模型啊
77:30 训练那一部分是相当相当的少的
77:33 他花了很多时间去讲
77:34 他整个设定长什么样子
77:36 画一个图告诉大家
77:38 所以在那么长的论文里面
77:39 就那么一点点地方讲你真正的干货
77:42 是一个比较奇怪的做法
77:44 这也是为什么
77:44 我们在之前
77:45 先给大家讲的 GPT 和 gpt 2这篇文章
77:48 再来讲 gpt 3
77:49 如果你直接读 gpt 3这篇文章的话
77:51 你会发现读起来还是不那么容易的
77:53 接下来是长达20页的结果
77:56 我们就不给大家一一的详细讲了
77:58 就给大家过一下比较有意思的一些图吧
78:01 下面第一个图
78:02 展现的是不同大小的模型
78:04 在训练的时候
78:05 他跟你的计算量的一个关系
78:07 x 轴表示的是计算量
78:10 你的Y轴表示的是你的验证的损失
78:13 他这个地方用验证损失
78:15 是因为他发现验证损失
78:17 跟你这些子任务上的精度是有一定关系的
78:20 所以能够很好的表示你预训练模型的一个好坏
78:23 就每一根线啊表示的是一个
78:27 参数的模型
78:28 当你训练时间变长的话
78:29 你的计算量会跟着增加
78:31 这个地方每一根线啊
78:32 表示的是一个不同设置的模型
78:35 这个黄色表示的是 GPT-3最大的那个模型
78:38 当这个线表示的是最小那个模型
78:40 当你随着你的训练的增加
78:43 那么你的计算量会增加
78:44 因为他算的是你到目前为止
78:46 所有的计算量
78:47 可以看到这个地方基本上就收敛了
78:49 虽然你的计算还在往上涨
78:51 但是你的损失没有再往下降
78:53 最好的一个权衡其实在这个地方
78:56 相对于计算量和损失来讲
78:58 最低的是这个点
78:59 就是说你训练到这个地方就差不多了
79:00 你不用往下训练了
79:02 如果你要往下训练的话
79:03 你把模型做的更复杂一点说
79:05 你把所有这些模型
79:06 他的最好的这个点啊
79:08 拉成一条线的话
79:10 你会发现这是一个叫做power law的分布
79:13 也就是说在你最好的情况下
79:15 就是说你找到一个合适的模型
79:17 而且不用训练过度训练的情况下
79:20 那么你随着你计算量的指数的增加
79:24 你的损失是线性的往下降
79:27 这个一直是机器学习的一个痛点啊
79:30 就是当你想
79:30 持续线性的提升你的精度的时候
79:32 你得不断的指数去翻你的数据量
79:36 数据量当然弄起来是很难的一件事情
79:39 二个是说你数据量增加之后
79:41 你的计算量也是跟着指数的增加
79:43 这个地方讲呢是我的数据固定的时候
79:46 我如果想线性的降低我的损失
79:49 我一样的计算量都得指数的往上增加
79:52 当然跟人类比还是差的太远了
79:54 人类的大脑啊
79:55 相当于一个60瓦的一个灯泡的耗能
79:58 然后人类在学习的时候
80:00 远远的不需要那么多的样本
80:02 你想想你学会阅读的时候
80:04 你就要读多少本书就行呢
80:05 你可能读小学语文那几本书就行呢
80:07 但是他这个地方
80:08 他把整个互联网上东西全部抓了下来
80:11 才能够学习到
80:12 可能跟人类相比
80:13 还是有一点差距的地方
80:15 所以我们还有很长的路要走啊
80:17 然后再往下面看很多这样子的图啊
80:19 他这个地方
80:19 x 轴还是表示的你模型的参数的大小
80:22 到后面这个线就是你最大的模型
80:24 然后你的Y轴是你的精度
80:26 这个地方是使用 ZeroShot 的最好的模型
80:29 而人在这个地方
80:30 然后在这个地方他发现
80:31 当你增加模型大小的时候
80:33 他当然是能够超越
80:35 目前最好的那些Zero Shot的算法
80:37 而且如果你使用 Few Shot的话
80:39 跟人类的精度还是有那么接近的地方
80:42 在这个地方
80:43 然后当然下面很多这样子的图啊
80:45 在这个地方他讲的是一个叫做 open domain 的一个QA 
80:50 就是在开放区的一个问答
80:52 然后他对比的是T5
80:54 T5 是来自于Google的一个算法
80:56 你可以认为是编码器解码器全部拿过来
80:59 BERT 用的是编码器
81:01 gpt 用的是解码器
81:02 T5用的是编码器解码器都有
81:04 然后你如果用 T5 做微调的话
81:06 gpt 其实你用啊FewShot 的或者是 one Shot的
81:10 他都比他要好了
81:12 然后你往下面翻的话
81:13 这个是另外一个 qa 的一个任务
81:15 然后这个是使用微调的时候
81:17 最好的一个精度
81:18 GPT  3最大的模型
81:20 已经跟他已经非常接近了
81:22 然后这个是机器翻译
81:24 每一根线表示的是一个语言
81:26 翻译到另外一个语言
81:28 实线是表示别人翻译到英语
81:30 那虚线表示英语翻到别人
81:32 你的Y轴用的是BLEU这个分数啊
81:34 这是机器翻译最常见的分数
81:36 然后有意思的是说
81:37 你看到别人翻到英语
81:39 通常来说比英语翻到别的语言要好
81:43 然后你往后面翻很远之后
81:44 你看到用 gpt 生成的一个新闻稿啊 标题啊
81:49 灰色部分是给 GPT-3的输入啊
81:51 后面这些黑的部分就是 gpt 写出来的
81:55 然后基本上你看一下
81:56 写的还似模似样的
81:58 然后这里面有年份
81:59 有各种数字呀
82:00 各种百分比啊就讲的似模似样的
82:03 所以这个地方有一点点可怕
82:04 GPT-3瞎扯起来真的是脸不红心不跳的
82:08 似模似样
82:09 然后后面又是一些样例
82:10 怎么让 GPT-3来做题 就是说
82:12 就是我告诉你一个词
82:13 他大概意义是什么
82:15 然后用这个词来造句
82:16 黑色就是 gpt 造出来的句子
82:18 他基本上 GPT-3给你写写作业是
82:20 没有问题的啊
82:22 那我们就很简单的给大家讲了一下实验
82:24 如果你是做这一块相关的话
82:26 你可以找到对应的那些数据
82:27 去仔细了解一下啊
82:29 如果 只是想知道他大概模型的效果的话
82:32 我们就这么简单就过去了
82:34 接下来我们来看一下第五章
82:35 讲的是这个模型的局限性
82:38 在这一章里面
82:39 作者列举了非常多的局限性
82:42 我们来稍微看一下他到底是什么
82:44 首先他说虽然我们比GPT2好很多啊
82:47 但是我在文本生成上面呢
82:49 还是比较弱的
82:51 就是如果我让 gpt3生成一个很长的文本的话
82:53 可能可能给了几段之后
82:55 他又把上面的东西重新过来写一下
82:58 所以如果你想让他来帮你写小说的话
83:00 就是比较难的
83:01 因为他很难得到一个剧情的人往前推
83:04 但如果你告诉他说
83:05 这一段我没有讲什么的话
83:07 他很有可能能帮你补全的似模似样
83:09 第二个是说 他说我有一些结构和算法上的局限性
83:13 他讲的一个主要的局限性是说
83:15 GPT-3因为用的是语言模式
83:17 他是往前看的
83:19 他不能像之前BERT 能够反过方向来看
83:21 这也是因为 gpt 使用的是 transformer 的
83:24 解码器的缘故
83:26 然后他讲的另外一个局限性是说
83:27 因为你训练是语言模型
83:29 每一次你要去预测下一个词
83:31 所以他这个地方是每一个词啊
83:34 他都是很均匀的去预测下一个词
83:37 他没有告诉你说哪个词比较重要
83:39 哪一个词不重要
83:41 我们知道在语言里面很多词都是一些
83:43 常见词但是没有太多意义的虚词
83:46 所以导致整个语言模型花很多时间学习这些虚词
83:49 还不像你真的要教小孩一样的
83:51 告诉你这个是划重点
83:53 这个才是要去记住的东西
83:56 当然他还有说因为我用的只是文本啊
83:58 所以我对别的东西没见过
84:00 比如说没见过 video 长什么样子
84:02 没见过真实的这些
84:04 物理的交互长什么样子
84:05 因为人在学习的时候
84:06 读书只是整个人的活动种在了一块
84:09 所以他也就是在这一块做比较好
84:12 但是别的方面他基本上是没有涉及的
84:14 他还讲了一个是你的样本有效性不够
84:17 因为你为了训练这个模型
84:18 我基本上整把整个网络上的文章
84:20 都给你下下来了
84:22 那对人来讲这个真的是太可怕了
84:24 另外一个问题作者说也可能不叫问题
84:27 就是不确信是说
84:28 你在做这种给你多个样本
84:31 在做上下文的学习的时候
84:33 他真的是去从头开始学习吗
84:36 他真的是说
84:37 我去通过你给我的样本学习
84:39 这个样本是长这样
84:41 还是说我就是
84:43 根据个样本
84:43 在我之前的文本里面找出相关的
84:46 然后把它记住就行了
84:47 就认出了这个任务
84:49 这两个当然不一样
84:50 我们当然喜欢说
84:51 你从头开始学这个途径
84:53 这样子的话
84:54 真的碰到一个你的训练样本上
84:55 没有出现过的任务的话
84:57 我也能够泛化过去
84:59 如果就是我
85:00 根据你的样本从我的训练
85:02 记忆里面把他相关的东西找出来的话
85:05 那就真的
85:06 最后拼的是你的训练数据的大小了
85:08 另外一个跟之前样本有效性的相关
85:11 就是说训练起来非常的贵
85:14 最后一个
85:14 GPT-3跟很多深度学习模型啊
85:17 都是无法解释的
85:18 就是我给你个输入
85:20 然后你返回
85:20 给我一个看上去很不错的输出
85:22 但我并不知道你是
85:24 怎么样得到你的输入的
85:26 你里面哪些权重真的起到作用
85:28 而且你整个决策是怎么做的
85:30 特别是对 GPT-3那么大的模型来讲
85:33 去找出里面这些
85:34 做关键决策这些全都是非常难的
85:37 所以我们最多能说
85:38 GPT-3真的就是大力出奇迹了
85:41 接下来是对 GPT-3可能那些影响的一些讨论
85:44 因为这个模型以及非常强大的
85:46 可以直接拿过去用了
85:47 就是说部署在生产环境里面
85:49 一旦你的部署到生产环境里面的话
85:51 那么肯定会对人
85:52 会对社会产生一些影响
85:54 最简单是他是不是安全的
85:56 大家不要觉得一个模型
85:58 他能够对人造成多大危害
86:00 如果你真的依赖一个模型
86:01 做一些很重要的决策的话
86:03 那当然可能会带来很大的影响
86:05 open ai 的很多工作有这样子的讨论
86:07 我觉得是非常好的
86:08 那表示这个团队是
86:10 有很大的社会责任感的
86:11 我们这里简单的给大家过一下
86:13 他首先说
86:14 我这个模型可能会被用来做坏事
86:17 在6.1.1里面讲到说
86:19 你有可能是散布一些不实的消息
86:22 生成一些垃圾邮件或者钓鱼邮件啊
86:25 然后论文造假呀
86:26 我们之前有看到他
86:28 生成的那些新闻稿啊
86:29 真的人是很难看出来区别的
86:32 我们读篇新闻的话
86:33 你们对里面的数字啊一些很多事情
86:35 我们通常不会下意识的去怀疑
86:38 他觉得你既然记者把他写出来
86:40 那么一定是你做过调查的
86:42 如果有人用 GPT-3
86:43 大量的生成这样子的文章的话
86:45 可能会有很多读者会去信里面的东西
86:48 虽然现在很多这样的过滤机制啊
86:50 比如说你的邮箱里面
86:51 会判断一封邮件是不是垃圾邮件
86:53 但如果 gpt 3
86:54 能够大量的生成这样子的文章的话
86:57 那么肯定是有一小部分能绕过这些机制
86:59 从而能够对人产生影响
87:02 他又讲了一下公平性啊偏见啊
87:04 比如在性别上
87:05 因为他下的文章里面
87:06 很有可能里面男性这种词居多
87:09 比如说你让 gpt 去回答一个侦探
87:11 是一个男人还是一个女人
87:13 那么 gpt 在很大的可能性上认为这是一个男人
87:16 接下来他 调查了一下 gpt
87:18 对一些性别的一些偏见
87:20 作者让 gpt 回答
87:22 he was very
87:23 或者 she was very 就是男性的是怎么样的
87:26 女性会怎么样的
87:27 然后他去判断一些词出现的概率
87:30 把那些比较偏见那些词拿出来
87:32 比如说对男性来说
87:33 GPT 可能生成他是比较男的
87:36 对女性来说他
87:37 很大概率会生成他是非常漂亮的
87:40 就漂亮这个词不是一个贬义词
87:43 但是漂亮意味着是说
87:45 你对女性的外表比较在意
87:47 这是一个偏见
87:48 第二个是对种族
87:49 比如说这一个
87:52 啊女人非常的什么你可以换成白的黄的黑的
87:56 然后下面这个图
87:57 表示的是不同大小模型
87:59 对不同种族的一些
88:01 正面还是负面的评价
88:03 这里0表示的是正常
88:04 正的是表示的是这这个种族比较正面的反馈
88:08 负数是表示比较负面的
88:11 对黑人就是这一根线
88:13 相对来说比较负面的
88:14 但是对于 asian 整体来说是比较正面的
88:17 虽然作为亚洲人
88:18 看到这个结果可能会比较开心
88:20 但是当你发现
88:21 一个模型对于不同种族的区别有那么大的时候
88:25 你可要注意到说可能换一个模型
88:27 那个模型可能是仇视亚洲人的
88:29 还有是可能有宗教啊
88:31 宗教之间相互歧视也是非常严重的
88:33 最后一点关于的是能耗
88:35 因为你训练 gpt 模型啊需要几百台机器
88:38 训练很多天
88:39 那么一台机器
88:40 那么就是几千瓦的能耗的话
88:42 那么训练下来
88:43 你的能耗也是相当夸张的
88:46 最后是他的结论
88:47 他说我们做了一个
88:48 有1,750亿参数的语言模型
88:51 然后在许多的 NLP 的任务上面我们做了
88:54 Zero Shot、One Shot、Few Shot的学习
88:57 在很多情况下
88:58 他能够媲美到使用更多 带标号数据的
89:01 基于微调的算法
89:03 然后他的一个卖点是能够生成
89:05 高质量的一些文本
89:07 让他们展示了一个
89:09 不用基于微调的一个可能性
89:11 然后我们对整个 gpt 啊 gpt 2
89:13 GPT-3这三个工作做一个评论
89:16 你可认为 gpt 是起了一个大早
89:18 他先把
89:19 transformer 这个模型拿过来做预训练
89:22 然后证明他在效果上很好
89:24 但是没想到在选择路线上
89:26 二选一的时候选了一条路
89:28 但是没想到另外一条路走的更容易点
89:30 也就是 bert 和他之后的工作
89:33 但作者没有气馁啊因为我有钱我有人
89:35 所以我一条路走到黑
89:37 第二就是把模型做的更大
89:38 然后尝试一个更难的问题
89:40 就是不在下游的任务上做微调
89:43 如果你发现你还是打不赢的话怎么办
89:46 那就再摇人吧
89:47 然后再准备一点钱
89:48 我做一个更大的100倍更大的模型出来
89:51 所以最后扳回一句
89:52 不管怎么样
89:53 gpt 系列给我们开了眼界啊
